{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utilities import my_show, my_gshow, my_read, my_read_g, my_read_cg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To compute contours, we need a binary image which we can get by applying thresholding or edge detection.  `findContours` will modify the source image (note:  as of OpenCV 3.2, this is no longer true - it does *not* modify the input image), so we will often make a copy if we need the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messi_c, messi_g = my_read_cg('data/messi.jpg')\n",
    "ret,thresh = cv2.threshold(messi_g,127,255,0)\n",
    "image, contours, hierarchy = cv2.findContours(thresh,\n",
    "                                              cv2.RETR_TREE,\n",
    "                                              cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_image = np.zeros_like(messi_c)\n",
    "contour_image = cv2.drawContours(contour_image, contours, -1, (128, 128, 128), 3) # -1 means \"draw all\"\n",
    "my_gshow(plt.gca(), contour_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt = my_read_g('data/bolt.png')\n",
    "my_gshow(plt.gca(), bolt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(bolt,127,255,cv2.THRESH_BINARY_INV)\n",
    "cont_img, contours, hierarchy = cv2.findContours(thresh, \n",
    "                                                 cv2.RETR_TREE, \n",
    "                                                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "# various moments are defined\n",
    "M = cv2.moments(contours[0])\n",
    "print(M.keys())\n",
    "\n",
    "# center of mass\n",
    "cx = int(M['m10']/M['m00']) # C_x = M_{10} / M_{00}  (center of mass of x)\n",
    "cy = int(M['m01']/M['m00']) # center of y\n",
    "print(cx, cy)\n",
    "\n",
    "# area\n",
    "area = cv2.contourArea(contours[0])\n",
    "print(area, M['m00']) # m00 is also area\n",
    "\n",
    "# perimeter\n",
    "perimeter = cv2.arcLength(contours[0], True) # True = close the curve\n",
    "print(perimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt = my_read_g('data/bolt.png')\n",
    "_, bolt = cv2.threshold(bolt, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "bolt2 = cv2.copyMakeBorder(bolt, 50,50,50,50,cv2.BORDER_CONSTANT)\n",
    "\n",
    "bolt4 = np.tile(bolt2, (2,2))\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4))\n",
    "my_gshow(axes[0], bolt4)\n",
    "\n",
    "cont_img, contours, hierarchy = cv2.findContours(bolt4, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# as of opencv 3, cont_img is not modifed ... i.e., same as bolt4\n",
    "my_gshow(axes[1], cont_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if objects are simple, len(contours) --> number of objects\n",
    "# but this won't hold for real-world images\n",
    "print(cont_img.shape, bolt4.shape)\n",
    "print(len(contours)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_cont = cv2.drawContours(np.zeros_like(bolt4, dtype=np.uint8), \n",
    "                             contours, -1, (255,0,0), 5)\n",
    "my_gshow(plt.gca(), just_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random warning: contours overlaying an edge may be lost\n",
    "cont = contours[0] # first contour object\n",
    "epsilon = 0.1*cv2.arcLength(cont,True)         # error tolerance for:\n",
    "approx  = cv2.approxPolyDP(cont,epsilon,True)  # smooth/simply curve via polynomials\n",
    "\n",
    "\n",
    "bolt4_color = cv2.cvtColor(bolt4, cv2.COLOR_GRAY2RGB)\n",
    "# WARNING:  arg[1] to drawCont MUST be a sequence OF sequences OF points;\n",
    "#            if it is a sequence of points, this will break (silently) and only the first\n",
    "#            point will be drawn (which you may not be able to see!)\n",
    "# 3.x drawContours returns image also, but it is ref. to same object\n",
    "highlight_bolt4 = cv2.drawContours(bolt4_color, [contours[0]], 0, (255,0,0), 5)\n",
    "my_show(plt.gca(), highlight_bolt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contours and Outlines (Hulls, Bounding Boxes, and Bounding Circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = cv2.convexHull(contours[0])\n",
    "bolt4_color = cv2.cvtColor(bolt4, cv2.COLOR_GRAY2RGB)\n",
    "hull_bolt4 = cv2.drawContours(bolt4_color.copy(), [hull], 0, (255,0,0), 5)\n",
    "my_show(plt.gca(), hull_bolt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.isContourConvex(contours[0]),\n",
    "      cv2.isContourConvex(hull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = cv2.boundingRect(contours[0])\n",
    "boxes = bolt4_color.copy()\n",
    "\n",
    "red, green = (255,0,0), (0,255,0)\n",
    "# add \"perpendicular\" (to axes) bounding box\n",
    "boxes = cv2.rectangle(boxes, (x,y), (x+w, y+h), red, 5)\n",
    "\n",
    "# weird return type: two points and an angle ... immediately convert\n",
    "# add \"rotated\" (parallel to major axis) bounding box\n",
    "rect = cv2.boxPoints(cv2.minAreaRect(contours[0])).astype(np.int64)\n",
    "boxes = cv2.drawContours(boxes, [rect], 0, green, 5)\n",
    "my_show(plt.gca(), boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = bolt4_color.copy()\n",
    "\n",
    "red, green = (255,0,0), (0,255,0)\n",
    "(x,y),radius = cv2.minEnclosingCircle(contours[0])\n",
    "center, radius = (int(x), int(y)), int(radius)  # really!?!\n",
    "others = cv2.circle(others, center, radius, red, 5)\n",
    "\n",
    "ellipse = cv2.fitEllipse(contours[0])\n",
    "others = cv2.ellipse(others, ellipse, green, 5)\n",
    "my_show(plt.gca(), others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (300, 300)\n",
    "orig = np.zeros(shape, dtype=np.uint8)\n",
    "orig[145:155,  50:250] = 255\n",
    "orig[50:250 , 145:155] = 255\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4))\n",
    "my_show(axes[0], orig, cmap='gray')\n",
    "\n",
    "cont_img, contours, hierarchy = cv2.findContours(orig.copy(),\n",
    "                                                 cv2.RETR_TREE,\n",
    "                                                 cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# maximal extent\n",
    "cross = contours[0].squeeze() # not a copy, drop dims of size 1\n",
    "big, small = cross.argmax(axis=0), cross.argmin(axis=0)\n",
    "\n",
    "west, north = cross[small] # upper left is (0,0)\n",
    "east, south = cross[big]\n",
    "\n",
    "cross_color = cv2.cvtColor(orig, cv2.COLOR_GRAY2RGB)\n",
    "for ext in [west, north, east, south]:\n",
    "    print(ext)\n",
    "    cross_color = cv2.circle(cross_color, (ext[0], ext[1]), 0, (255, 0, 0), 10)\n",
    "my_show(axes[1], cross_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# various \"statistics\" of contours:\n",
    "cont = contours[0]\n",
    "\n",
    "x,y,w,h   = cv2.boundingRect(cont)\n",
    "area      = cv2.contourArea(cont)\n",
    "hull      = cv2.convexHull(cont)\n",
    "hull_area = cv2.contourArea(hull)\n",
    "\n",
    "aspect_ratio = w / h\n",
    "rect_area    = w * h\n",
    "extent       = area / rect_area\n",
    "\n",
    "solidity   = area / hull_area\n",
    "equiv_diam = np.sqrt(4 * area / np.pi)\n",
    "\n",
    "orientation_angle = cv2.fitEllipse(cont)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(orig)\n",
    "cv2.drawContours(mask, [cont], 0, 255, -1) #-1 means \"fill me\"\n",
    "\n",
    "# r,c entries\n",
    "np.transpose(np.nonzero(mask))  # r1, c2; r2, c2; ....\n",
    "\n",
    "# to actually index these points on the original image\n",
    "orig[np.nonzero(mask)] # row 1, row 2, .....     col 1, col 2, ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(orig)\n",
    "cv2.drawContours(mask, [cont], 0, 255, -1) # fill the contour in\n",
    "cv2.findNonZero(mask).shape                # \"many\" 1x2 things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll just verify that min/max vals are \"on\"\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(orig, mask=mask)\n",
    "cv2.mean(orig, mask=mask)\n",
    "# min_val, max_val, min_loc, max_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Contour Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hull convexity defects\n",
    "hull = cv2.convexHull(cont, returnPoints = False)\n",
    "defects = cv2.convexityDefects(cont,hull)\n",
    "\n",
    "img = orig.copy()\n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# furth is the furthest point from hull segment (aka, distance to defect)\n",
    "for start, end, furth, dist in defects.squeeze():\n",
    "    start, end, furth = map(tuple, cont.squeeze()[[start, end, furth]])\n",
    "    cv2.line(img, start, end, (255,0,0),5)\n",
    "    cv2.circle(img, furth, 5, (0,255,0), -1)\n",
    "my_show(plt.gca(), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi, messi_g = my_read_cg('data/messi.jpg')\n",
    "\n",
    "# NOTE: at row 280, col 330\n",
    "ball_soi = messi_g[280:340, 330:390]\n",
    "\n",
    "h,w = ball_soi.shape\n",
    "\n",
    "# matching methods\n",
    "#methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "#            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "matches = cv2.matchTemplate(messi_g, ball_soi, cv2.TM_CCOEFF_NORMED)\n",
    "min_max = cv2.minMaxLoc(matches)\n",
    "\n",
    "print(min_max)     \n",
    "print(min_max[3])  # NOTE:  at x,y (horizontal, vertival) 330, 280\n",
    "x,y = min_max[3]   #        matches are given in these terms\n",
    "\n",
    "# drawing is done in x-y (cartesian grid) terms\n",
    "cv2.rectangle(messi, (x,y), (x+h, y+h), (0,0,255), 4)\n",
    "my_show(plt.gca(), messi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi, messi_g = my_read_cg('data/messi.jpg')\n",
    "\n",
    "ball_soi = messi_g[280:340, 330:390] # at row 280, col 330\n",
    "\n",
    "h,w = ball_soi.shape\n",
    "\n",
    "matches = cv2.matchTemplate(messi_g, ball_soi, cv2.TM_CCOEFF_NORMED)\n",
    "THRESH = .9\n",
    "rows, cols = np.where(matches > THRESH)\n",
    "print(len(rows))\n",
    "print(rows, cols)\n",
    "\n",
    "# convert from r,c to x,y\n",
    "x,y = cols[0], rows[0]\n",
    "cv2.rectangle(messi, (x,y), (x+h, y+h), (0,0,255), 4)\n",
    "my_show(plt.gca(), messi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Backprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = my_read('data/messi.jpg')\n",
    "messi_hsv = cv2.cvtColor(messi, cv2.COLOR_RGB2HSV) # HSV space\n",
    "\n",
    "pitch = messi_hsv[280:320, 20:140].copy()\n",
    "\n",
    "# calculating ROI histogram\n",
    "pitch_hist = cv2.calcHist([pitch], [0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    "\n",
    "# normalize histogram and apply backprojection\n",
    "cv2.normalize(pitch_hist, pitch_hist, 0,255, cv2.NORM_MINMAX)\n",
    "result = cv2.calcBackProject([messi_hsv], [0,1], pitch_hist, [0,180,0,256], 1)\n",
    "\n",
    "# Now convolute with circular disc\n",
    "disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "result = cv2.filter2D(result, -1, disc)\n",
    "\n",
    "# threshold\n",
    "_,thresh = cv2.threshold(result,50,255,0)\n",
    "thresh = np.repeat(thresh[:,:,np.newaxis], 3, axis=2)\n",
    "\n",
    "print(thresh.shape)\n",
    "res = cv2.bitwise_and(messi_hsv,thresh)\n",
    "\n",
    "my_show(plt.gca(), cv2.cvtColor(res, cv2.COLOR_HSV2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we can manually achieve the same result using \"raw\" NumPy operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in \"numpy\" esque code\n",
    "messi = my_read('data/messi.jpg')\n",
    "messi_hsv = cv2.cvtColor(messi, cv2.COLOR_RGB2HSV)\n",
    "pitch = messi_hsv[280:320, 20:140].copy()\n",
    "\n",
    "M = cv2.calcHist([pitch],[0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    "I = cv2.calcHist([messi_hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    "\n",
    "# very similar to np.interp [0,min] [255,max]\n",
    "cv2.normalize(M, M, 0, 255, cv2.NORM_MINMAX)\n",
    "cv2.normalize(I, I, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# conversion to pseudo-probabilities\n",
    "# deal with divide by zero\n",
    "R = np.minimum(M / np.where(I, I, 1E-20), 1) # could also take from M\n",
    "\n",
    "result = R[messi_hsv[:,:,0].ravel(), \n",
    "           messi_hsv[:,:,1].ravel()].reshape(messi_hsv.shape[:2])\n",
    "\n",
    "disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "result = cv2.filter2D(result, -1, disc).astype(np.uint8)\n",
    "cv2.normalize(result, result, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# threshold and binary AND\n",
    "_,thresh = cv2.threshold(result,50,255,0)\n",
    "thresh   = np.repeat(thresh[:,:,np.newaxis], 3, axis=2)\n",
    "res      = cv2.bitwise_and(messi_hsv, thresh)\n",
    "\n",
    "my_show(plt.gca(), cv2.cvtColor(res, cv2.COLOR_HSV2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by basic thresholding to get outlines of our foreground:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins, coins_g = my_read_cg('data/water_coins.jpg')\n",
    "_, thresh = cv2.threshold(coins_g, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(18,14))\n",
    "my_show(axes[0], coins)\n",
    "my_gshow(axes[1], coins_g)\n",
    "my_gshow(axes[2], thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(cleaned, kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area (regions that are far from black)\n",
    "dist_transform = cv2.distanceTransform(cleaned, cv2.DIST_L2, 5)\n",
    "sure_fg = cv2.threshold(dist_transform, \n",
    "                        0.7*dist_transform.max(), 255, 0)[1].astype(np.uint8)\n",
    "\n",
    "# Finding unknown region\n",
    "unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(9,6))\n",
    "my_gshow(axes[0,0], cleaned)\n",
    "my_gshow(axes[0,1], sure_bg)\n",
    "axes[0,2].set_visible(False)\n",
    "\n",
    "axes[0,0].set_title('Cleaned')\n",
    "axes[0,1].set_title('\"Sure\" BG\\n(in black)')\n",
    "\n",
    "my_gshow(axes[1,0], dist_transform)\n",
    "my_gshow(axes[1,1], sure_fg)\n",
    "my_gshow(axes[1,2], unknown)\n",
    "\n",
    "axes[1,0].set_title(\"Post-Dist X-form\")\n",
    "axes[1,1].set_title('\"Sure\" FG\\n(in white)')\n",
    "axes[1,2].set_title('Unknown Region')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that setup, let's label background 1, the sure foreground objects 2,...,n+1, and the unknown regions 0.  Watershed will attempt to label the unknown pixels (that are currently labeled 0) with one of the positive values:  1, 2, 3, ..., n+1.  So, at the end, pixels will belong to either background or one of n objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known connected components (bg 0, components 1+) --> bg 1, components 2+\n",
    "markers = cv2.connectedComponents(sure_fg)[1] + 1\n",
    "markers[unknown==255] = 0 # enforce this brutally\n",
    "obj_ct = len(set(markers.flat))\n",
    "\n",
    "print(\"Found\", obj_ct, \"pseudo-objects (connected components)\")\n",
    "\n",
    "def magic(idx):\n",
    "    ' create a custom color mapping to take marker # --> good color '\n",
    "    cmap = plt.cm.tab20b if idx < 20 else plt.cm.tab20c\n",
    "    idx = idx if idx < 20 else idx - 20\n",
    "    return cmap(idx)\n",
    "magic_table   = np.array([magic(i) for i in range(obj_ct)])\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15,6))\n",
    "my_show(axes[0], magic_table[markers])  # full array indexes back into color table\n",
    "\n",
    "watershed = cv2.watershed(coins, markers) # apply watershed to coins from \"markers\" seeds \n",
    "coins[markers == -1] = [255,0,0] # ^^^ markers is modified; -1 is boundaries\n",
    "\n",
    "my_show(axes[1], watershed)\n",
    "my_show(axes[2], coins)\n",
    "\n",
    "# Note: you might like to compare this with hough circle transform on the same image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we manually define a rectangle and use it to initialize grabcut.  There are a few moving parts here:\n",
    "  * to keep the C code happy, we have to pre-allocate some arrays for GrabCut (`mask`, `bgm`, `fgm`)\n",
    "  * the result of grabcut is an array with values `[0,1,2,3]` where\n",
    "    * 0,2 represent \"sure\" and \"probable\" background and \n",
    "    * 1,3 represent \"sure\" and probable foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = my_read('data/messi.jpg')\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "green, gray = [0, 255, 0], [127, 127, 127]\n",
    "\n",
    "#\n",
    "# we'll manually define a rectangle to initialize grabcut\n",
    "#\n",
    "rect  = (50,50,450,290) # manual rectangle\n",
    "messi_box = cv2.rectangle(messi.copy(), (50,50), (400, 240), green, 5)\n",
    "my_show(axes[0], messi_box)\n",
    "\n",
    "#\n",
    "# setup grab cut and reprocess mask\n",
    "#\n",
    "# these are basically placeholder memory allocations\n",
    "mask = np.zeros(messi.shape[:2], np.uint8)\n",
    "bgm, fgm = [np.zeros((1,65))] * 2\n",
    "mask, _, _ = cv2.grabCut(messi, mask, rect, bgm, fgm, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "#\n",
    "# In the new mask image, pixels will be marked with four values\n",
    "# denoting background/foreground\n",
    "#\n",
    "# So we modify the mask such that all \n",
    "# 0-pixels and 2-pixels are put to 0 (ie background) and \n",
    "# 1-pixels and 3-pixels are put to 1(ie foreground pixels)\n",
    "# (i.e., mapper[0] == mapper[2] == 0 (bg)\n",
    "#        mapper[1] == mapper[3] == 1 (fg))\n",
    "mapper = np.array([0, 1, 0, 1], dtype=np.uint8)\n",
    "mask = mapper[mask]\n",
    "\n",
    "#\n",
    "# compute display results (gray background to distinguish)\n",
    "#\n",
    "foreground = messi * mask[:,:,np.newaxis]\n",
    "background = np.full_like(messi, gray) * (1-mask[:,:,np.newaxis])\n",
    "result = background + foreground\n",
    "\n",
    "my_show(axes[1], result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Template Matching\n",
    "\n",
    "Use `data/mario_coins.png` and `data/mario_one_coin.png` to draw boxes around all the coins in full image.  Try using both `matchTemplate` and [fixme:  match via histogram]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, img_g = my_read_cg('data/mario_coins.png')\n",
    "template   = my_read_g('data/mario_one_coin.png')\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contours, Thresholds, and Histograms\n",
    "Open the apple image and find its contours.  Compare the RGB histograms of the whole image versus the histograms of the apple itself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2,figsize=(12,8))\n",
    "\n",
    "apple, grey_apple = my_read_cg('data/apple.png')\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Better Messi\n",
    "\n",
    "Above, we used a manual rectangle.  But, much of the point of image processing is to do these tasks in an *automated* way.  Can you construct a pipeline that goes from the raw image, programmatically construct an initializing rectangle, and then perform grabcut?  [Hint:  get some edges, use morphology to flesh out a legitimate outline, and then calculate a bounding box to use as the rectangle.]\n",
    "\n",
    "If you succeed with that task, you might get to a point where you get \"most\" of Messi with some unwanted background.  Now, try to initialize the grabcut routine with a foreground/background mask instead of a rectangle.  Note, the values for the mask array are [0,1,2,3] == \"sure background\", \"sure foreground\", \"probable background\", \"probable foreground\".  You may need to play around with how you get from a binary mask (with just two values) to your 4-value mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi, messi_g = my_read_cg('data/messi.jpg')\n",
    "edges = cv2.Canny(messi_g, 100, 200, L2gradient=True)\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(12,6))\n",
    "\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi, messi_g = my_read_cg('data/messi.jpg')\n",
    "edges = cv2.Canny(messi_g, 100, 200, L2gradient=True)\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,6))\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 OpenCV3 (Forge)",
   "language": "python",
   "name": "opencv-forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
