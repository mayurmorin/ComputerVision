{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StartUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen most of our foundational pieces, we can do the \"common startup tasks\" that we will usually need in a notebook (or in a script file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utilities import my_show, my_gshow, my_read, my_read_g, my_read_cg\n",
    "\n",
    "img_dir = '../common/'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that we also imported some names from a `utilities.py` file.  Basically, we took the code for those functions from the Week_01 notebook and put them in a module.  This is a *really good idea*.  Why?  Primarily because of D-R-Y:  don't repeat yourself.  Cutting and pasting that code into many different scripts and into cells in notebooks leads to massive inefficiency.  Imagine if the code has been duplicated by cut-n-paste in five different places.  Now, when you want to update it (add a new feature, fix a bug, add unit tests) you have to track down all five locations and repeatedly fix them.  With the code in a re-used module, you minimize this sort of repeated effort.  For the record, here's what `utilities.py` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat utilities.py  # you can also use !cat (unix-y) or !more (windows-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit8 / c unsigned 8-bit int - addition results in wrapping/modulo/clocklike arithmetic\n",
    "np.uint8([100]) + np.uint8([200]), 300 - 2**8, 300 % 2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2 operations are a bit different.  they perform \"clipping\"  \n",
    "cv2.add(np.uint8([100]), np.uint8([200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is simlar to the far more complicated (and memory consuming)\n",
    "# 1.  upconvert (to a type that won't overflow) 2. clipped addition 3. downconvert\n",
    "arr1, arr2 = np.uint8([100]), np.uint8([200])\n",
    "np.clip(arr1.astype(np.uint16) + arr2.astype(np.uint16), 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml   = my_read(img_dir+'data/ml.png')\n",
    "frog = my_read(img_dir+'data/frog.jpg')\n",
    "\n",
    "min_r, min_c = (min(ml.shape[0], frog.shape[0]), \n",
    "                min(ml.shape[1], frog.shape[1]))\n",
    "\n",
    "# blending of two images:\n",
    "# by:  img1 * wgt1 + img2 * wgt2 + wgt3\n",
    "#      addWeights(img1, wgt1, img2, wgt2, wgt3)\n",
    "dst = cv2.addWeighted(  ml[:min_r, :min_c], 0.7,\n",
    "                      frog[:min_r, :min_c], 0.3, 0)\n",
    "my_show(plt.gca(), dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place logo in corner of messi\n",
    "logo, messi = map(my_read, [img_dir+'data/opencv-logo.png', img_dir+'data/messi.jpg'])\n",
    "\n",
    "# technique for creating slices programmatically\n",
    "# i.e., create code that does indexing/slicing in arr[:, a:b, :c]\n",
    "shape = logo.shape[:-1]\n",
    "corner = [slice(0,n) for n in shape] + [slice(None)]  # fancy:  [:logo.shape[0], :logo.shape[1], :]\n",
    "print(corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi[corner] = logo\n",
    "my_show(plt.gca(), messi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.eye(3)\n",
    "img[1,2] = 1\n",
    "\n",
    "print(img)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title(\"No argument\")\n",
    "methods = ['nearest', 'bilinear', 'bicubic']\n",
    "for idx, method in enumerate(methods, 1):\n",
    "    axes[idx].imshow(img, interpolation=method)\n",
    "    axes[idx].set_title(f'{repr(method)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dealing with Colorspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv color converters\n",
    "import itertools as it\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    ' helper that make n-len groups out of iterable; last is padded with fillvalue'\n",
    "    args = [iter(iterable)] * n # repeated refs, so no duplicates, all advance\n",
    "    return it.zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "color_names = (i for i in dir(cv2) if i.startswith('COLOR_BGR'))\n",
    "print(\"\\n\".join(str(g) for g in grouper(color_names, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB and Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange gets 0:255\n",
    "# [] * 3 gets 3 channels\n",
    "# meshgrid gets cross product (cartesian product) of all possibilities\n",
    "# stack gets 256x256x256x3 array of these (-1 makes it on inner most dimension)\n",
    "# reshape (-1,ndim) gets them into num-of-input-arrays columns\n",
    "def cartesian_product(*arrays):\n",
    "    ' helper to generate flattened cross-product (combinations) from sequence of arrays '\n",
    "    ndim = len(arrays)\n",
    "    return np.stack(np.meshgrid(*arrays), axis=-1).reshape(-1, ndim)    \n",
    "\n",
    "base, dims = np.arange(256), 3\n",
    "print(cartesian_product(*[base]*3).shape,\n",
    "      np.stack(np.meshgrid(*[base]*dims), axis=-1).reshape(-1,dims).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R,G,B = 0,1,2\n",
    "\n",
    "rb = cartesian_product(np.arange(256), np.arange(256)).reshape(256,256,2)\n",
    "# if that's too mind blowing, here's a less general version:\n",
    "# rb = np.stack(np.meshgrid(np.arange(256), np.arange(256)), axis=-1)\n",
    "\n",
    "fig, axes = plt.subplots(2,5,figsize=(12,5))\n",
    "axes_it = axes.T.flat\n",
    "for g in [0,63,127,191,255]:\n",
    "    # create panel of rgb panels:  start with g, add rb\n",
    "    rgb = np.full((256,256,3), g, dtype=np.uint8)\n",
    "    rgb[:,:,[R,B]] = rb \n",
    "\n",
    "    # show color plot\n",
    "    ax = next(axes_it)\n",
    "    my_show(ax, rgb, origin='lower', interpolation=None)\n",
    "    ax.set_title('G={}'.format(g))\n",
    "    \n",
    "    # create and show grays\n",
    "    gray = cv2.cvtColor(rgb,cv2.COLOR_RGB2GRAY)\n",
    "    my_gshow(next(axes_it), gray, origin='lower', interpolation=None)\n",
    "\n",
    "axes[1,0].axis('on')\n",
    "axes[1,0].set_xlabel('R')\n",
    "axes[1,0].set_ylabel('B')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB and HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In OpenCV:\n",
    "\n",
    ">For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. Different softwares use different scales. So if you are comparing OpenCV values with them, you need to normalize these ranges.\n",
    "\n",
    "And, recall from the slides, a few general notes about the HSV colorspace:\n",
    "  * V/S trade off black/white\n",
    "  * in cone models, s is white is distance from cone axis\n",
    "  * v is black is distance from cone point towards the ice cream\n",
    "  * hue walks around a circle of colors (can map from $[0.0,2\\pi]$ to $[0,179]$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D # needed for projection=3d\n",
    "\n",
    "rgb_pts = np.empty((len(colors.TABLEAU_COLORS),3))\n",
    "hsv_pts = np.empty((len(colors.TABLEAU_COLORS),3))\n",
    "for idx, name in enumerate(colors.TABLEAU_COLORS):\n",
    "    # we'll look into the color names more in  a few minutes\n",
    "    rgb = colors.to_rgb(c=name)\n",
    "    hsv = colors.rgb_to_hsv(rgb)\n",
    "\n",
    "    rgb_pts[idx]=rgb\n",
    "    hsv_pts[idx]=hsv\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(1,2, subplot_kw={'projection':'3d'}, figsize=(12,6))\n",
    "for ax, pts, labels in zip(axes,\n",
    "                           [rgb_pts, hsv_pts],\n",
    "                           [list(\"RGB\"), list(\"HSV\")]):\n",
    "    seperated = list(zip(*pts))\n",
    "    ax.scatter3D(*seperated, c=rgb_pts, s=50)\n",
    "    ax.set_xlabel(labels[0]); ax.set_ylabel(labels[1]); ax.set_zlabel(labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting note:  saturations are mostly pretty high (>.8)\n",
    "#                    one near .5 and .05\n",
    "\n",
    "# we can \"unroll\" the cone to 2D using a constant saturation \n",
    "# this projection \"flattens\" the view from the front-left face of the 3D cube\n",
    "ax = plt.gca()\n",
    "# hsv_pts[:,1] = np.mean(hsv_pts[:,1]) # use mean as our slice\n",
    "ax.scatter(hsv_pts[:,0], hsv_pts[:,2], c=rgb_pts, s=50) # s here is size arg.\n",
    "#ax.set_xlim(-.05,1.05)\n",
    "#ax.set_ylim(-.05,1.05)\n",
    "ax.set_xlabel('H')\n",
    "ax.set_ylabel('V');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting by Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color by name from matplotlib\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "def cv2_rgb_to_hsv(rgb):\n",
    "    ' use cv2 to convert an rgb value to an hsv value '\n",
    "    rgb = rgb.reshape(1,1,-1)             # ugly, fake a 1 pixel image\n",
    "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)[0,0] # undo \"fake\" image\n",
    "    return hsv\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "color_name = 'lightsalmon'\n",
    "mpl_rgba = np.float64(mcolors.to_rgba(color_name))\n",
    "mpl_hsv = mcolors.rgb_to_hsv(mpl_rgba[:-1])\n",
    "print(\"mpl values: \", mpl_rgba, mpl_hsv)\n",
    "\n",
    "cv2_rgb = np.uint8(mpl_rgba[:-1] * 255)  # map [0.0,1.0] -> [0,255]\n",
    "cv2_hsv = cv2_rgb_to_hsv(cv2_rgb)\n",
    "print(\"cv2 values: \", cv2_rgb, cv2_hsv)\n",
    "print(\"manual conversion (mpl->cv2):\", np.round(mpl_hsv * [180,255,255]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixel = cv2_hsv\n",
    "img_hsv = np.tile(pixel, (300,300,1))\n",
    "img_rgb = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "my_show(plt.gca(), img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking by Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def track_blue(frame):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    rgb_blue = np.array([0,0,255]).astype(np.uint8).reshape(1,1,-1)\n",
    "    hsv_blue_mid = cv2.cvtColor(rgb_blue, cv2.COLOR_RGB2HSV)\n",
    "    h_blue,_,_ = hsv_blue_mid.flatten()\n",
    "\n",
    "    lwr_blue = np.array([h_blue-10,  50,  50]).astype(np.uint8)\n",
    "    upr_blue = np.array([h_blue+10, 255, 255]).astype(np.uint8)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lwr_blue, upr_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorful = my_read(img_dir+\"data/fuzzyballs2.png\")\n",
    "selected = track_blue(colorful)\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(10,5))\n",
    "my_show(axes[0], colorful)\n",
    "my_show(axes[1], selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = my_read_g(img_dir+'data/apple.png')\n",
    "hist = cv2.calcHist([apple], [0], None, [256], [0,256]) # src imgs, color channels, mask\n",
    "                                                        # num bins, range (half-open-right interval)\n",
    "print(hist.shape)\n",
    "hist[[0,128,164,255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(apple, 256, [0,255]) # note: closed interval\n",
    "print(hist.shape)\n",
    "hist[[0,128,164,255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use precomputed bin counts\n",
    "plt.hist(range(256), weights=hist, bins=256);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(apple.ravel(), 256, [0,255]); # or flatten and let plt.hist do the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = my_read(img_dir+'data/apple.png')\n",
    "# docs (for C++) imply you can do multiple channels at a time, but it fails :(\n",
    "for idx, color in enumerate(['r', 'g', 'b']):\n",
    "    hist = cv2.calcHist([apple],[idx],None,[256],[0,256])\n",
    "    plt.plot(hist, color = color)\n",
    "    plt.xlim([-5,260])\n",
    "    \n",
    "# lots of red.  not too surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = my_read_g(img_dir+'data/apple.png')\n",
    "\n",
    "# reduce contrast (squash intensities)\n",
    "# new min:  100, new max: 175\n",
    "new = np.interp(apple, [apple.min(), apple.max()], [125, 175]).astype(np.uint8)\n",
    "\n",
    "# equalize using CDF technique\n",
    "equalized = cv2.equalizeHist(new)\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(12,6))\n",
    "for idx, an_apple in enumerate([apple, new, equalized]):\n",
    "    # vmin/vmax set enforced min/max gray scale values ... without them\n",
    "    # 125 -> 0 ... 175 --> 255 and linearly interpolated\n",
    "    print(\"min: {} max: {}\".format(an_apple.min(), an_apple.max()))\n",
    "    my_gshow(axes[0, idx], an_apple, vmin=0, vmax=255)    \n",
    "    hist = cv2.calcHist([an_apple], [0], None, [256], [0,256])\n",
    "    axes[1,idx].plot(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare there methods of normalizing wrt the CDF\n",
    "\n",
    "def method1(img):\n",
    "    hist,_ = np.histogram(img,256,[0,256])\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    mask = cdf!=0\n",
    "    cdf_nz = cdf[mask]\n",
    "    mn, mx = cdf_nz.min(), cdf_nz.max()\n",
    "\n",
    "    cdf[mask] = (cdf_nz - mn) * 255 / (mx - mn)\n",
    "    return cdf[img]\n",
    "\n",
    "def method2(img):\n",
    "    hist,_ = np.histogram(img,256,[0,256])\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    mask = cdf!=0\n",
    "    cdf_nz = cdf[mask]\n",
    "    mn, mx = cdf_nz.min(), cdf_nz.max()\n",
    "\n",
    "    cdf[mask] = np.interp(cdf_nz, [mn, mx], [0,255])\n",
    "    return cdf[img]\n",
    "\n",
    "def method3(img):\n",
    "    hist,_ = np.histogram(new,256,[0,256])\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    # from website:  we can get away with filling zeros in the lookup table\n",
    "    # because no pixel has those value (so it never needs to be looked up)\n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "    return cdf[img]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3,figsize=(12,6))\n",
    "\n",
    "apple = my_read_g(img_dir+'data/apple.png')\n",
    "new = np.interp(apple, [apple.min(), apple.max()], [125, 175]).astype(np.uint8)\n",
    "\n",
    "other_args = {\"vmin\":0, \"vmax\":255, 'cmap':'gray'}\n",
    "\n",
    "my_show(axes[0,0], apple, **other_args)\n",
    "my_show(axes[0,1], new, **other_args)\n",
    "axes[0,2].set_visible(False)\n",
    "\n",
    "results = []\n",
    "for idx, method in enumerate([method1, method2, method3], 0):\n",
    "    my_show(axes[1,idx], method(new), **other_args)\n",
    "    results.append(method(new))\n",
    "\n",
    "print(\"All Similar Results?\", \n",
    "      all([np.allclose(results[0], results[1]), \n",
    "           np.allclose(results[0], results[2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram normalization makes low values lower and high values higher\n",
    "# --> outliers *get worse*!\n",
    "\n",
    "# contrast limited adaptive hist. equal.\n",
    "multi = my_read_g(img_dir+'data/tsukuba.png')\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "clahe_equal = clahe.apply(multi)\n",
    "\n",
    "global_equal = cv2.equalizeHist(multi)\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(16,4))\n",
    "\n",
    "other_args = {\"vmin\":0, \"vmax\":255, 'cmap':'gray'}\n",
    "my_show(axes[0], multi, **other_args)\n",
    "my_show(axes[1], global_equal, **other_args)\n",
    "my_show(axes[2], clahe_equal,  **other_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = my_read(img_dir+'data/messi.jpg')\n",
    "messi_hsv = cv2.cvtColor(messi, cv2.COLOR_RGB2HSV)\n",
    "hist  = cv2.calcHist([messi_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "\n",
    "# this is ... not ... great\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(hist, interpolation='nearest', cmap='hot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm as mpl_LogNorm\n",
    "\n",
    "h,s,v = cv2.split(messi_hsv)\n",
    "#_,_,_,cb_img = plt.hist2d(h.ravel(),s.ravel(),18)\n",
    "# log scale let's small values stand out more wrt big values\n",
    "_,_,_,cb_img = plt.hist2d(h.ravel(),s.ravel(),18, norm=mpl_LogNorm());\n",
    "plt.colorbar(cb_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Foreground and Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's be more subtle\n",
    "logo, messi = map(my_read, [img_dir+'data/opencv-logo.png', img_dir+'data/messi.jpg'])\n",
    "logo_fg = np.where(logo > 0)\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "messi[logo_fg] = logo[logo_fg]\n",
    "my_show(axes[0], messi, title=\"Looks Good w Interpolation\")\n",
    "my_show(axes[1], messi, interpolation=None, title=\"Less Good w/o Interp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo  = my_read(img_dir+'data/opencv-logo.png')\n",
    "messi = my_read(img_dir+'data/messi.jpg')\n",
    "\n",
    "\n",
    "# we were lucky, opencv logo was \"on\" or \"off\".\n",
    "# more generally, but not most generally, we can threshold\n",
    "# we'll dive into this in more detail shortly\n",
    "logo_gray = cv2.cvtColor(logo,cv2.COLOR_RGB2GRAY)\n",
    "ret, mask = cv2.threshold(logo_gray, 10, 255, cv2.THRESH_BINARY)\n",
    "mask_inv  = cv2.bitwise_not(mask)\n",
    "\n",
    "fig, axes = plt.subplots(1,4,figsize=(10,4))\n",
    "\n",
    "my_show(axes[0], logo)\n",
    "my_gshow(axes[1], logo_gray)\n",
    "my_gshow(axes[2], mask, title='logo as foreground')\n",
    "my_gshow(axes[3], mask_inv, title='logo as background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messi_roi = messi[:logo.shape[0], :logo.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messi_roi.shape, mask_inv.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image as background + foreground\n",
    "\n",
    "# background is messi where there isn't logo\n",
    "\n",
    "# create background from messi\n",
    "# logo  \"on\" --> messi off --> drop messi pixel\n",
    "# logo \"off\" --> messi on  --> grab messi pixel\n",
    "\n",
    "# this is convenient, compared to logical ops with array and mask of different kinds\n",
    "# mask-ed points go to zero\n",
    "bg = cv2.bitwise_and(messi_roi, messi_roi, mask=mask_inv)\n",
    "my_show(plt.gca(), bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foreground is from the logo\n",
    "# logo 'on' --> want this pixel\n",
    "fg = cv2.bitwise_and(logo, logo, mask=mask)\n",
    "my_show(plt.gca(), fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty direct ... only one pixel from fg/bg is \"on\" at any given position\n",
    "# b/c of our masking\n",
    "combined = cv2.add(bg, fg)\n",
    "my_show(plt.gca(), combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to:\n",
    "(logo>10).shape  # this is channel by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, let's get that effect without having to convert channels:\n",
    "active_roi = (logo>10).any(axis=2)\n",
    "silent_roi = np.logical_not(active_roi)\n",
    "active_roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alternative to np.newaxis:  np.expand_dims(mask_inv, -1)\n",
    "fg = np.bitwise_and(logo, mask[:,:,np.newaxis])\n",
    "bg = np.bitwise_and(messi_roi, mask_inv[:,:,np.newaxis])\n",
    "combined = cv2.add(bg, fg)\n",
    "my_show(plt.gca(), combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Thresholding Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple gradient\n",
    "\n",
    "# this also works, but tile seems nicer\n",
    "# gradient = (np.zeros((300, 256*2), dtype=np.uint8) + \n",
    "#             np.repeat(np.arange(0,256, dtype=np.uint8),2))\n",
    "\n",
    "# repeat to get 0,0,1,1,2,2,3,3,...,... then tile it for horizontals\n",
    "one_row = np.repeat(np.arange(0,256, dtype=np.uint8),2)\n",
    "gradient = np.tile(one_row, (300,1))\n",
    "my_show(plt.gca(), gradient, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [cv2.THRESH_BINARY, cv2.THRESH_BINARY_INV, cv2.THRESH_TRUNC,\n",
    "           cv2.THRESH_TOZERO, cv2.THRESH_TOZERO_INV]\n",
    "titles = ['BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(12,9))\n",
    "axes = axes.flat\n",
    "\n",
    "ax = next(axes)\n",
    "my_show(ax, gradient, cmap='gray')           \n",
    "ax.set_title(\"Original\")\n",
    "\n",
    "for m, t, ax in zip(methods, titles, axes):\n",
    "    # src, midpoint, > map to, method\n",
    "    _, res = cv2.threshold(gradient,127,255,m)\n",
    "    my_show(ax, res, cmap='gray')\n",
    "    ax.set_title(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood-Sensitive Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(12,9))\n",
    "axes = axes.flat\n",
    "\n",
    "uneven = cv2.imread(img_dir+'data/uneven-illumination.png',0)\n",
    "ax = next(axes)\n",
    "my_show(ax, uneven, cmap='gray')           \n",
    "ax.set_title(\"Original\")\n",
    "\n",
    "_, bin_th = cv2.threshold(uneven,127,255,cv2.THRESH_BINARY)\n",
    "ax = next(axes)\n",
    "my_show(ax, bin_th, cmap='gray')           \n",
    "ax.set_title(\"Binary Threshold (@127)\")\n",
    "\n",
    "methods = [cv2.ADAPTIVE_THRESH_MEAN_C, cv2.ADAPTIVE_THRESH_GAUSSIAN_C]\n",
    "titles  = [\"Neighborhood Mean\", \"Neighborhood Gaussian\"]\n",
    "\n",
    "for m, t, ax in zip(methods, titles, axes):\n",
    "    # src, midpoint, > map to, method\n",
    "    res = cv2.adaptiveThreshold(uneven,255,m, \n",
    "                                cv2.THRESH_BINARY, # or BIN_INV\n",
    "                                11, # neighborhood size (11x11),\n",
    "                                2) # value subtracted from mean/gauss sum before comparison\n",
    "    my_show(ax, res, cmap='gray')\n",
    "    ax.set_title(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize=(12,4))\n",
    "axes = axes.flat\n",
    "\n",
    "shape = (300,300)\n",
    "\n",
    "orig = np.zeros(shape, dtype=np.uint8)\n",
    "orig[75:225, 75:225] = 255\n",
    "my_show(next(axes), orig, cmap='gray')\n",
    "\n",
    "# not ultra efficient ... but it works\n",
    "# (note)\n",
    "blur = np.random.randint(0,256,size=shape).astype(np.uint8)\n",
    "blurred = np.where(np.random.uniform(size=shape) > .3, orig, blur)\n",
    "my_show(next(axes), blurred, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otsu's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a very nice presentation of Otsu's method:\n",
    "  * http://www.labbookpages.co.uk/software/imgProc/otsuThreshold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,2,figsize=(12,4))\n",
    "axes = axes.flat\n",
    "\n",
    "# Otsu's thresholding\n",
    "next(axes).hist(blurred.flatten(), 256, log=True)\n",
    "# this seems weird:  shouldn't it be black and white?!?\n",
    "thresh, th_otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(\"Optimal Thresh is\", thresh)\n",
    "my_show(next(axes), th_otsu, cmap='gray', interpolation=None) # force us to see what's there!\n",
    "\n",
    "reblurred = cv2.GaussianBlur(blurred, (5,5), 0) # neighborhood, variance?\n",
    "next(axes).hist(reblurred.flatten(), 256);\n",
    "thresh, th_otsu = cv2.threshold(reblurred, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(\"Optimal Thresh is\", thresh)\n",
    "my_show(next(axes), th_otsu, cmap='gray')# also: interpolation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Transformations of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def size_me(img):\n",
    "    ' given 80dpi, find size of image in inches from pixel dims '\n",
    "    dpi = 80\n",
    "    height, width, *depth = img.shape\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "    return figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = my_read(img_dir+'data/messi.jpg')\n",
    "fig, ax = plt.subplots(1,1,figsize=size_me(messi))\n",
    "my_show(ax, messi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom in (make bigger)\n",
    "res = cv2.resize(messi, None, fx=2, fy=2, interpolation = cv2.INTER_AREA)\n",
    "# slight use of matlab style api to avoid plt.subplots(1,1,...) call for just one axis \n",
    "plt.figure(figsize=size_me(res)) \n",
    "my_show(plt.gca(), res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom out (make smaller)\n",
    "height, width = messi.shape[:2]\n",
    "res = cv2.resize(messi, (int(.5*width), int(.5*height)), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "plt.figure(figsize=size_me(res))\n",
    "my_show(plt.gca(), res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two primary types of transformations:\n",
    " * warpAffine:  2x3 matrix      (parallel lines stay parallel)\n",
    " * warpPerspective: 3x3 matrix\n",
    "\n",
    "$x_{\\text{shift}}$ is amount to the right (negative, indicates to the left)\n",
    "$y_{\\text{shift}}$ is amount down (negative indicates up)\n",
    "\n",
    "$$M = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & x_{\\text{shift}} \\\\\n",
    "0 & 1 & y_{\\text{shift}}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_gray = my_read_g(img_dir+'data/messi.jpg')\n",
    "\n",
    "height, width = messi_gray.shape   # r,c -> x,y\n",
    "\n",
    "x_shift, y_shift = 100, 50  \n",
    "\n",
    "M = np.array([[1, 0, x_shift],\n",
    "              [0, 1, y_shift]], dtype=np.float32)\n",
    "res = cv2.warpAffine(messi_gray, M, (width, height)) # arguments in x,y terms\n",
    "\n",
    "my_show(plt.gca(), res, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_gray = my_read_g(img_dir+'data/messi.jpg')\n",
    "\n",
    "height, width = messi_gray.shape   # r,c -> x,y\n",
    "\n",
    "scale_factor = 0.75\n",
    "\n",
    "M = np.array([[scale_factor, 0, 0],\n",
    "              [0, scale_factor, 0]], dtype=np.float32)\n",
    "res = cv2.warpAffine(messi_gray, M, (int(width * scale_factor), \n",
    "                                     int(height * scale_factor))) # arguments in x,y terms\n",
    "\n",
    "plt.figure(figsize=size_me(res))\n",
    "my_show(plt.gca(), res, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$M = \n",
    "\\begin{bmatrix}\n",
    "\\cos(\\theta) & - \\sin(\\theta) \\\\\n",
    "\\sin(\\theta) & \\cos(\\theta)\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Becomes:\n",
    "\n",
    "\n",
    "$$M = \n",
    "\\begin{bmatrix}\n",
    " \\alpha & \\beta  & (1-\\alpha) x_{\\text{center}} -      \\beta y_{\\text{center}} \\\\\n",
    "-\\beta  & \\alpha &      \\beta x_{\\text{center}} + (1-\\alpha) x_{\\text{center}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$\\begin{align}\n",
    "\\alpha &= scale \\cos(\\theta) \\\\\n",
    "\\beta  &= scale \\sin(\\theta) \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D((width/2,height/2), 45, 1)\n",
    "res = cv2.warpAffine(messi_gray, M, (width, height)) # args in xy terms (not rc terms)\n",
    "my_show(plt.gca(), res, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to define an affine transform by definine three before and after points.  With three points before and after a transform, the affine matrix can be inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (300,300)\n",
    "orig = np.zeros(shape, dtype=np.uint8)\n",
    "orig[75:225, 75:225] = 255\n",
    "\n",
    "# NOTE:  play around with these to get a feel for what they do!\n",
    "# args in xy terms (not rc terms)\n",
    "pts1 = np.float32([[75,75], [75,225], [225,225]])\n",
    "pts2 = np.float32([[75,75], [75,150], [225,225]])\n",
    "M = cv2.getAffineTransform(pts1,pts2)\n",
    "res = cv2.warpAffine(orig, M, shape)\n",
    "\n",
    "print(M)\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(12,4))\n",
    "my_show(axes[0], orig, cmap='gray')\n",
    "my_show(axes[1], res, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perspective transform:  straight lines -> straight lines\n",
    "\n",
    "# pts in r,c terms (:sadface:)\n",
    "rows, cols = messi_gray.shape\n",
    "pts1 = np.float32([[0,0],[rows-1,0], [0,cols-1], [rows-1, cols-1]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[250,250]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "res = cv2.warpPerspective(messi_gray, M, (cols, rows)) # r,c -> x,y terms\n",
    "\n",
    "my_show(plt.gca(), res, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Series of Transition Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick two images and create a series of 20 images that show a transition from the first image to the second.  You can investigate playing the images as a movie, but creating a video is beyond the scope of today's discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open an image and draw a line and a circle on it.\n",
    "\n",
    "Create a tiny image (10 pixels by 10 pixels) and use `cv2.line` to draw a line on it from the top-left corner to the midpoint of the right hand side.  Note that `cv2.line` is \"thinking\" in terms of (x,y) coordinates.  Show the resulting images with and without interpolation.  Look at the contents of the underlying array.  You might also play around with the `thickness` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `np.where` to find the coordinates of the endpoints of the line you just drew.  Fortunately, the end points will be at the start and end of the returned values.  Unfortuantely, `np.where` thinking about indexing in terms of rows and columns (r,c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the coordinates you extracted with `np.where`, draw a rectangle that covers the line.  Careful!  Do rows map to an x-coordinate or to a y-coordinate?  Surprise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is a painful and annoying lesson, you only have to learn it once!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Test Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our square test image, uses a geometric transformation to create a diamond (a rotated squared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with RGB and Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take an image and create pairs of plots showing (1) a grayscale image for a given RGB color channel and (2) the normalized histogram for that channel.  You'll need to dig into the documentation for `plt.hist` and pay attention to the arguments for: (1) `weights`, (2) `bins`, and (3) `normed`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Detection Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we developed a \"blue detector\" that could be used to find blue regions of an object.  Let's generalize that.   Write a function `inrange_hsv(img, hue, span)` that returns a mask for `img` that *keeps* hue values between $[h-span, h+span]$.  As we mentioned above, OpenCV uses values in $[0,179]$ to store hues.  And, the values are clock-like or modulo ... they wrap around.  Thus, the value 5 is effectively 10 points away from the value 175.  Taking this in to consideration, write `inrange_hsv` so that it will work for any input hue `hue`.  Hint:  keep making use of `inRange` as we did above, but consider using it multiple multiples times and combining the results.\n",
    "\n",
    "Test it out by looking for \"pure\" red (RGB=(255,0,0)) in our friend, the apple.  Play around with the `span` to see what value lets you can capture the maximum apple with minimum background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exercise Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Try different cv2 interpolators ... compare with mpl interpolators\n",
    "  * Play around with differences between np.bitwise_and and cv2.bitwise_and\n",
    "  * Use addWeighted and look at results with and w/o interpolation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 OpenCV3 (Forge)",
   "language": "python",
   "name": "opencv-forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
