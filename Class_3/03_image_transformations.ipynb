{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utilities import my_show, my_gshow, my_read, my_read_g, my_read_cg, size_me\n",
    "\n",
    "img_dir = '../common/'\n",
    "# keep np.array display under control\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculus in Pixel-space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box = np.zeros((15, 15), dtype=np.int8)\n",
    "box[4:11, 4:11] = 1.0\n",
    "my_gshow(plt.gca(), box, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import my_gshow\n",
    "\n",
    "box = np.zeros((15, 15), dtype=np.int8)\n",
    "box[4:11, 4:11] = 1.0\n",
    "my_gshow(plt.gca(), box, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a line across the middle .... \n",
    "line = box[5:6, :] # 5:6 to keep 2D\n",
    "line_p = np.diff(line) # line \"prime\" aka derivative\n",
    "\n",
    "print(line)\n",
    "print(line_p)\n",
    "print(line_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a line across the middle .... \n",
    "line = box[5:6, :] # 5:6 to keep 2D\n",
    "\n",
    "\n",
    "print(line)\n",
    "print(line_p, line_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, derivative has values [-1, 0, 1] ... \n",
    "# these get mapped to [0, 128, 255] \n",
    "# (aka, black, gray, white) inside of imshow\n",
    "\n",
    "fig,axes = plt.subplots(2, 1, figsize=(6,1), sharex=True)\n",
    "my_gshow(axes[0], line, interpolation=None)\n",
    "my_gshow(axes[1], line_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integral Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not too hard to construct integral images out of NumPy primatives.  It's also good practice with NumPy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,4*4+1).reshape(4,4)\n",
    "print(arr)\n",
    "integral = arr.cumsum(axis=1).cumsum(axis=0)\n",
    "integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1 = (1,1)\n",
    "pt2 = (2,2)\n",
    "print(6 + 7 + 10 + 11,\n",
    "      integral[2,2] - integral[0,2] - integral[2,0] + integral[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_integral_img(img):\n",
    "    return img.cumsum(axis=1).cumsum(axis=0)\n",
    "\n",
    "def area(integral_image, pt1, pt2):\n",
    "    # assume pt1 is the outer point and fix if necessary\n",
    "    outer_pt, inner_pt = pt1, pt2\n",
    "    if sum(pt1) < sum(pt2):\n",
    "        outer_pt, inner_pt = inner_pt, outer_pt\n",
    "\n",
    "    # the squares\n",
    "    outer_sq  = integral_image[outer_pt]\n",
    "    inner_sq  = integral_image[inner_pt[0]-1, inner_pt[1]-1]\n",
    "    \n",
    "    # the rectangles\n",
    "    tall_rect = integral_image[outer_pt[0], inner_pt[1]-1]\n",
    "    wide_rect = integral_image[inner_pt[0]-1, outer_pt[1]]\n",
    "    \n",
    "    # inclusion-exclusion\n",
    "    return outer_sq - tall_rect - wide_rect + inner_sq\n",
    "\n",
    "img = np.arange(1,4*4+1).reshape(4,4)\n",
    "integral_img = make_integral_img(img)\n",
    "\n",
    "pt1, pt2 = (2,2), (1,1)\n",
    "\n",
    "area(integral_img, pt1, pt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Aside:  Kernel (aka Neighborhood or Local Region) Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilty of a 2 .... given by \n",
    "# (1) taking all combinations of events, \n",
    "# (2) computing sums, \n",
    "# (3) return counts of 2 events divided by total number of events\n",
    "# also, we know this is 1/6 * 1/6\n",
    "d1, d2 = np.meshgrid(*[np.arange(1,7)]*2)\n",
    "sums = d1 + d2\n",
    "event_table = dict(zip(*np.unique(d1+d2, return_counts=True)))\n",
    "print(\"{:.4f} {:.4f}\".format(event_table[2] / sums.size, 1/6 * 1/6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_table[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of a 2:  \n",
    "# P_twodice(Total) = sum_part P_onedie(part) * P_onedie(Total-part)\n",
    "# P_twodice(2) = sum_part P_onedie(part) * P_onedie(2-part)\n",
    "# [note, the only valid part here is part = 1 ... all others are \"too big\"]\n",
    "die = np.full(6, 1/6.0)\n",
    "print(die)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can think:  invert second, align, multiple and add\n",
    "np.convolve(die, die, mode='full') # all probabilities in event space (pads outside with effective zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in general, the pdf of a sum of events is the convolution of the component events!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another way to think about convolutions is as \"sliding windows\"\n",
    "# in the example above, to get, say a total of 7\n",
    "# we can fix a point 7 and slide the two arrays past (one in reverse order) ... \n",
    "# and when they add up to seven, we take that sum-product\n",
    "\n",
    "# say we flip the second array and start running them past each other\n",
    "# we start with a 6,6 ... then we 6,5; 5,6 .... and so on\n",
    "# eventually, they are lined up such that we get 1,6; ... 6,1 ...\n",
    "# *all* of our ways of getting 7 ... we can take that dot-product and we have our \n",
    "# probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example is taking a moving average\n",
    "# since the second array is \"symmetric\" about its middle\n",
    "# this greatly simplifies our mental arithmetic  ... \n",
    "# we just slide it past, computing dot-products (weighted sums) as we go\n",
    "# our \"total\" is simply the center point we are at ... \n",
    "#       aka, we align the weight-window centered at the point we are trying to fill\n",
    "values = np.arange(10.0)\n",
    "kernel = np.full(3, 1/3)\n",
    "print(values, kernel, \n",
    "      np.convolve(values, kernel, mode='valid'), # you can try full/same here and see the edge effects\n",
    "      sep='\\n')\n",
    "\n",
    "print(\"*\" * 20)\n",
    "\n",
    "values = np.array([3,6,9,3,12,15])\n",
    "print(values, kernel, \n",
    "      np.convolve(values, kernel, mode='valid'),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's all great, but we are working with images.  we can do the same thing in two-D\n",
    "from scipy.signal import convolve2d as ss_convolve2d\n",
    "box = np.zeros((15, 15), dtype=np.int8)\n",
    "box[4:11, 4:11] = 1.0\n",
    "\n",
    "size = 3 # adjust me!\n",
    "kernel = np.full((size,size), 1/size**2)\n",
    "out = ss_convolve2d(box, kernel, mode='same') \n",
    "# with same or full, we have to pad ... \n",
    "#      can use wrapping (around the image)\n",
    "#      symmetric (mirroring back from the edge)\n",
    "#      fill value\n",
    "\n",
    "print(out.shape)\n",
    "my_gshow(plt.gca(), out, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here's what's happening in the top-left corner of the white box:\n",
    "import seaborn as sns\n",
    "\n",
    "box = np.zeros((5,5), np.uint8)\n",
    "box[3:, 3:] = 1.0\n",
    "kernel = np.full((3,3), 1/3**2)\n",
    "out = ss_convolve2d(box, kernel, mode='same', boundary='symm')\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(12,4))\n",
    "\n",
    "kwargs = dict(annot=True, fmt=\".3f\", cbar=False)\n",
    "sns.heatmap(box,    ax=axes[0], **kwargs)\n",
    "sns.heatmap(kernel, ax=axes[1], **kwargs)\n",
    "sns.heatmap(out,    ax=axes[2], **kwargs)\n",
    "\n",
    "[ax.axis('off') for ax in axes]\n",
    "fig.tight_layout();\n",
    "\n",
    "# experiment with different padding to see what happens to the bottom-right square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proc:  Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((500,500), dtype=np.uint8)\n",
    "circle = cv2.circle(img,(250,250), 100, 255, -1)\n",
    "\n",
    "blur = np.random.randint(0,256,size=img.shape).astype(np.uint8)\n",
    "blurred = np.where(np.random.uniform(size=img.shape) > .25, img, blur)\n",
    "\n",
    "my_show(plt.gca(), blurred, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"erode\" away the foreground (foreground == white)\n",
    "# pixel is on if entire kernel-neighborhood is on\n",
    "# so, inside is good, outside is off\n",
    "#     borders of foreground:  will be reduced\n",
    "#     more will become background\n",
    "# enhances background; removes noise in background ... add noise in foreground\n",
    "\n",
    "# \"dilate\" adds to the foreground (white)\n",
    "# pixel is on if ANY kernel-neighborhood is on\n",
    "# inside - good; outside - off; border - expanded\n",
    "# enhances foreground; removes noise in foreground ... adds noise in background\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(12,8))\n",
    "fig.tight_layout()\n",
    "kernel = np.ones((7, 7), dtype=np.uint8)\n",
    "\n",
    "for idx, base in enumerate([circle, blurred]):\n",
    "    eroded = cv2.erode(base, kernel, iterations = 3)\n",
    "    dilated = cv2.dilate(base, kernel, iterations = 3)\n",
    "\n",
    "    my_gshow(axes[idx,0], base,    title='original image')\n",
    "    my_gshow(axes[idx,1], eroded,  title='eroded')\n",
    "    my_gshow(axes[idx,2], dilated, title='dilated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opening: dilate(erode(img))  ... aka, erode it, then dilate it\n",
    "# remove outside noise (false foreground); remove local peaks\n",
    "# count objects\n",
    "# opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# closing:  erode(dilate(img))\n",
    "# remove inside noise (false background)\n",
    "# used as a step in connected-components analysis\n",
    "# closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# ^^^^ iterations of these are erode(erode(dilate(dilate())))\n",
    "#      i.e. e^i(d^i(img))\n",
    "\n",
    "# gradient = dilation - erosion ... finds bounary\n",
    "# gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "# these two isolate brigher/dimmer (tophat/blackhat) than their surroundings\n",
    "# tophat:  image - opening\n",
    "# tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "# blackhat:  closing - image\n",
    "# blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurring and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_dir+'data/opencv-logo.png')\n",
    "\n",
    "kernel_size = (5,5)\n",
    "kernel = np.full(kernel_size, 1/np.prod(kernel_size))\n",
    "dst = cv2.filter2D(img,-1,kernel)\n",
    "\n",
    "print(img.shape, dst.shape)\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(8,6))\n",
    "my_show(axes[0], img)\n",
    "my_show(axes[1], dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.blur(img, kernel_size) # average of kernel_size neighborhood\n",
    "boxf  = cv2.boxFilter(img, -1, kernel_size, normalize=False) #???\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(12,6))\n",
    "my_show(axes[0], img)\n",
    "my_show(axes[1], blur)\n",
    "my_show(axes[2], boxf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss  = cv2.GaussianBlur(img, kernel_size, 5)\n",
    "\n",
    "\n",
    "dots = np.random.randint(0,256,size=img.shape).astype(np.uint8)\n",
    "dotted = np.where(np.random.uniform(size=img.shape) > .3, img, dots)\n",
    "median = cv2.medianBlur(dotted, kernel_size[0])  # 5 --> 5x5 neighborhood\n",
    "\n",
    "fig,axes = plt.subplots(2,2,figsize=(12,12))\n",
    "my_show(axes[0,0], img)\n",
    "my_show(axes[0,1], dotted)\n",
    "my_show(axes[1,0], gauss)\n",
    "my_show(axes[1,1], median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need a better image example for bilateral filtering\n",
    "# bilateral refers to smoothing both intensities AND colors\n",
    "# \"edge preserving\".  produces a \"water color painting effect\" when repeated\n",
    "saved = cv2.bilateralFilter(dotted,9,100, 50)\n",
    "my_show(plt.gca(), saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proc: Image Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unsure of object sizes in an image - \n",
    "# work with images of different resolutions and find objects in each\n",
    "# \"stack\" of images is an image pyramid\n",
    "\n",
    "# gaussian:  lower resolution  <---- higher resolution by removing rows/cols then gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = my_read(img_dir+'data/messi.jpg')\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=size_me(messi))\n",
    "my_show(ax, messi)\n",
    "\n",
    "# pyrDown == \"reduce\" == downSample(gaussian(img)) == downSample(gaussian conv. img)\n",
    "gaussian_pyr_1 = cv2.pyrDown(messi)\n",
    "fig, ax = plt.subplots(1,1,figsize=size_me(gaussian_pyr_1))\n",
    "my_show(ax, gaussian_pyr_1)\n",
    "\n",
    "gaussian_pyr_2 = cv2.pyrDown(gaussian_pyr_1)\n",
    "fig, ax = plt.subplots(1,1,figsize=size_me(gaussian_pyr_2))\n",
    "my_show(ax, gaussian_pyr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored = cv2.pyrUp(cv2.pyrUp(gaussian_pyr_2))  # back to full size ... lost information\n",
    "fig, ax = plt.subplots(1,1,figsize=size_me(restored))\n",
    "my_show(ax, restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laplacian L_lvl = G_lvl - expanded(G_{lvl + 1})\n",
    "# https://www.cs.utah.edu/~arul/report/node12.html\n",
    "laplacian_messi = messi - cv2.pyrUp(cv2.pyrDown(messi))\n",
    "fig, ax = plt.subplots(1,1,figsize=size_me(laplacian_messi))\n",
    "my_show(ax, laplacian_messi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_0 = messi[:256, :512] # powers of two to make halving/doubling happy; could also pad out to next power of two\n",
    "g_1 = cv2.pyrDown(g_0) # REDUCE(messi)\n",
    "g_2 = cv2.pyrDown(g_1)\n",
    "\n",
    "l_0 = g_0 - cv2.pyrUp(g_1)   # by simple algebra:  img = g0 = l_0 + UP(g1)\n",
    "l_1 = g_1 - cv2.pyrUp(g_2)\n",
    "base = g_2\n",
    "\n",
    "print(g_1.shape, l_1.shape)\n",
    "\n",
    "# more algebra:\n",
    "# g_0 = l_0 + UP(g_1) = l_0 + UP(l_1 + UP(g2)) = l_0 + UP(l_1 + UP(base))\n",
    "\n",
    "# typically stored the \"laplacian pyramid\" which is l_0 .... l_n-1 and the \"base\" which is g_n\n",
    "# then conceptually (not strict addition):  base + l_n-1 + l_0 --> original\n",
    "# sort of a x_0 + diffs representation\n",
    "\n",
    "restored_1 = l_0 + cv2.pyrUp(g_1)\n",
    "restored_2 = l_0 + cv2.pyrUp(l_1 + cv2.pyrUp(base))\n",
    "fig, ax = plt.subplots(1,3,figsize=(12,4))\n",
    "my_show(ax[0], g_0)\n",
    "my_show(ax[1], restored_1)\n",
    "my_show(ax[2], restored_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyramids for Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME:  this could be an exercise answer\n",
    "#         i.e., do the \"manual\" process with apple/orange\n",
    "#         that we showed with Messi (but improved by generate_pyramids)\n",
    "apple = my_read(img_dir+'data/apple.png')\n",
    "orange = my_read(img_dir+'data/orange.png')\n",
    "\n",
    "def generate_pyramids(img, lvls):\n",
    "    gp = [img.copy()]\n",
    "    lp = []\n",
    "    for i in range(lvls-1):\n",
    "        curr_gp = gp[-1]\n",
    "        next_gp = cv2.pyrDown(curr_gp)\n",
    "        next_lp = curr_gp - cv2.pyrUp(next_gp, dstsize=curr_gp.shape[:2])\n",
    "        lp.append(next_lp)\n",
    "        gp.append(next_gp)\n",
    "\n",
    "    lp.append(gp[-1])\n",
    "    return gp,lp\n",
    "\n",
    "NUM_LVLS = 6\n",
    "\n",
    "gp_a, lp_a = generate_pyramids(apple, NUM_LVLS)\n",
    "gp_o, lp_o = generate_pyramids(orange, NUM_LVLS)\n",
    "\n",
    "print(\"\\n\".join(str([gp.shape, lp.shape]) for gp,lp in zip(gp_a, lp_a)))\n",
    "\n",
    "# manually recreate from gp_2 --> ... and from gp_3 --> ...\n",
    "restored_apple_1 = lp_a[0] + cv2.pyrUp(lp_a[1] + cv2.pyrUp(gp_a[2]))\n",
    "restored_apple_2 = lp_a[0] + cv2.pyrUp(lp_a[1] + cv2.pyrUp(lp_a[2] + cv2.pyrUp(gp_a[3])))\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "my_show(ax[0], restored_apple_1)\n",
    "my_show(ax[1], restored_apple_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_upped(a, b):\n",
    "    return cv2.pyrUp(a, dstsize=b.shape[:2]) + b\n",
    "    \n",
    "def generate_pyramids(img, lvls):\n",
    "    gp = [img.copy()]\n",
    "    lp = []\n",
    "    for i in range(lvls-1):\n",
    "        curr = gp[-1]\n",
    "        next_ = cv2.pyrDown(curr)\n",
    "        next_lp = curr - cv2.pyrUp(next_, dstsize=curr.shape[:2])\n",
    "        lp.append(next_lp)\n",
    "        gp.append(next_)\n",
    "\n",
    "    lp.append(gp[-1])\n",
    "    return gp,lp\n",
    "\n",
    "import functools as ft\n",
    "def reconstruct(lp_mask, lp_left, lp_right):\n",
    "    blended_lp = []\n",
    "    for lp_m, lp_l, lp_r in zip(lp_mask, lp_left, lp_right):\n",
    "        wgt = lp_m.astype(np.float64) # FIXME.  this appears to have no effect\n",
    "        new_lvl = (wgt * lp_l) + ((1-wgt) * lp_r)\n",
    "        blended_lp.append(new_lvl.astype(np.uint8))\n",
    "    return ft.reduce(add_upped, reversed(blended_lp))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(8,8))\n",
    "fig.tight_layout()\n",
    "\n",
    "apple = my_read(img_dir+'data/apple.png')\n",
    "orange = my_read(img_dir+'data/orange.png')\n",
    "mask = np.zeros((240,240,3), dtype=np.uint8)\n",
    "mask[:, 120:, :] = 1\n",
    "# mask[:, :120] = 1  # there are some artifacts using this mask\n",
    "\n",
    "my_show(axes[0,0], apple)\n",
    "my_show(axes[0,1], orange)\n",
    "\n",
    "NUM_LVLS = 7\n",
    "gp_a, lp_a = generate_pyramids(apple, NUM_LVLS)\n",
    "gp_o, lp_o = generate_pyramids(orange, NUM_LVLS)\n",
    "mask_gp, _ = generate_pyramids(mask, NUM_LVLS)\n",
    "\n",
    "    \n",
    "final = reconstruct(mask_gp, lp_a, lp_o)\n",
    "my_show(axes[1,0], final, title='pyramid merge')\n",
    "\n",
    "cols = apple.shape[1]\n",
    "raw_merge = np.hstack([orange[:,:cols//2],\n",
    "                       apple[:,cols//2:]])\n",
    "my_show(axes[1,1], raw_merge, title='raw merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Gradients via Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = np.zeros((500,500), dtype=np.uint8)\n",
    "box[150:350, 150:350] = 1.0\n",
    "my_gshow(plt.gca(), box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply Sobel and Laplacian filters directly with opencv.  For the Sobel filters, teh arguments are which direction to compute.  So, `sobel_x` is assigned a Sobel filter that responds to vertical gradient changes (walking across rows of the underlying matrix).  `sobel_y` responds to horizontal changes (walking up/down columns of the matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is written simply, but if we have to update anything, ugh\n",
    "laplacian = cv2.Laplacian(box, cv2.CV_64F, ksize=5)\n",
    "sobel_x   = cv2.Sobel(box, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y   = cv2.Sobel(box, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_xy  = cv2.Sobel(box, cv2.CV_64F, 1, 1, ksize=5)\n",
    "\n",
    "fig, axes = plt.subplots(1,5,figsize=(12,3))\n",
    "for ax, smoother in zip(axes.flat,\n",
    "                        [box,laplacian, sobel_x, sobel_y, sobel_xy]):\n",
    "    my_gshow(ax, smoother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,5,figsize=(12,3))\n",
    "axes = axes.flat\n",
    "common_args = {'ddepth':cv2.CV_64F, 'ksize':5}\n",
    "\n",
    "# original and laplacian\n",
    "my_gshow(next(axes), box)\n",
    "my_gshow(next(axes), cv2.Laplacian(box, **common_args))\n",
    "\n",
    "# sobel filters; note (1,1) has very faint contents in corners\n",
    "for ax, (dx, dy) in zip(axes, [(1,0), (0,1), (1,1)]):\n",
    "    full_args = dict(common_args, dx=dx, dy=dy)\n",
    "    sob = cv2.Sobel(box, **full_args)\n",
    "    my_gshow(ax, sob)\n",
    "\n",
    "print(\"Top left corner values:\\n\", sob[147:153, 147:153])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we needed to compare these edge detectors many times, we might want to (1) write a helper function to encapsulate the process and (2) deal with issues like keeping both edges as \"positive\" values. Remember how we had +1 and -1 when we computed np.diff above - we can address that by taking the absolute value of the edges we find.  The net result is both the \"white-to-black\" and \"black-to-white\" have a response of 1.  Also, we can threshold the results to force black and white images for increased contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_filters(orig, axes, both_edges=False, enhance=False, **common_args):\n",
    "    if both_edges: # to keep edges, cv needs to keep sign info\n",
    "        common_args['ddepth'] = cv2.CV_64F\n",
    "    my_gshow(next(axes), orig)\n",
    "\n",
    "    sobel_args = [(1,0), (0,1), (1,1)]\n",
    "    sobels = [cv2.Sobel(orig, **dict(common_args, dx=dx, dy=dy)) for  dx,dy in sobel_args]\n",
    "    filters = [cv2.Laplacian(orig, **common_args)] + sobels\n",
    "    \n",
    "    if both_edges:\n",
    "        filters = [np.absolute(f).astype(np.uint8) for f in filters]\n",
    "    if enhance:\n",
    "        filters = [cv2.threshold(f, 1, 255, cv2.THRESH_BINARY)[1] for f in filters]\n",
    "    \n",
    "    for f in filters:\n",
    "        my_gshow(next(axes), f)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = np.zeros((500,500), dtype=np.uint8)\n",
    "box[150:350, 150:350] = 1.0\n",
    "fig, axes = plt.subplots(1,5,figsize=(12,3))\n",
    "\n",
    "# note, 8U implies unsigned ... clipped at 0\n",
    "results = show_filters(box, axes.flat, both_edges=True, \n",
    "                       enhance=True, ddepth=cv2.CV_8U, ksize=5)\n",
    "\n",
    "fig,axes = plt.subplots(1,5,figsize=(12,3))\n",
    "my_gshow(axes[0], np.uint8([[255]]),vmin=0) # bleh:  black out first square\n",
    "for f, ax in zip(results, axes[1:]):\n",
    "    my_gshow(ax, f[125:175, 125:175], interpolation=None)\n",
    "    ax.set_title('Nonzero: {}'.format(np.count_nonzero(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so that was painful, right?  well, now we can resuse it.  the next cell is easy!\n",
    "height, width = box.shape\n",
    "M = cv2.getRotationMatrix2D((width/2,height/2), 45, 1)\n",
    "diamond = cv2.warpAffine(box, M, (width, height))\n",
    "\n",
    "fig, axes = plt.subplots(1,5,figsize=(12,3))\n",
    "\n",
    "show_filters(diamond, axes.flat, both_edges=True, enhance=True, ddepth=cv2.CV_8U, ksize=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have edges, we may need to find and group together pixels as a-hypothetical-object (although we don't really have any concept beyond \"groups of pixels\"). One step in that process is to find the distances from a pixel to a boundary.  Two interesting distance metrics to use here are:\n",
    "  * `cv2.DIST_L2`.  The L2 norm:  Euclidean distance, aka pythagorean theorem), \n",
    "  * `cv2.DIST_L1`.  Chessboard distance for a rook that can only move one square at a time:   allows moves on row and col. \n",
    "  * `cv2.DIST_C`.   Chessboard distance for a king: allows moves on row, col, and diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image -> threshold -> edges -> invert (non-edge is white)\n",
    "sobel_xy  = np.absolute(cv2.Sobel(diamond, cv2.CV_64F, 1, 1, ksize=5)).astype(np.uint8)\n",
    "sobel_xy = cv2.threshold(sobel_xy, 1, 255, cv2.THRESH_BINARY)[1]\n",
    "np.unique(sobel_xy, return_counts=True)\n",
    "sobel_xy = cv2.subtract(255,sobel_xy) # invert\n",
    "my_gshow(plt.gca(), sobel_xy)\n",
    "\n",
    "# distances from a point to a white point\n",
    "dist = cv2.distanceTransform(sobel_xy, cv2.DIST_L2, 0)\n",
    "my_gshow(plt.gca(), dist, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label is grouping to nearest edge (both sides of edge grouped together)\n",
    "dist, labels = cv2.distanceTransformWithLabels(sobel_xy, cv2.DIST_L2, 5)\n",
    "print(labels.shape,\n",
    "      labels[:5,:5],\n",
    "      labels[250:255, 250:255], \n",
    "      (labels.min(), labels.max()),sep=\"\\n*******\\n\")\n",
    "my_gshow(plt.gca(), labels, interpolation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradients on the Diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an image of several concentric rings and take the derivative of the image across its diagonal.  Hint:  check out `np.diag`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIXME EXERCISE\n",
    "# create a small staircase and apply morphology to it\n",
    "# try different ops and kernels\n",
    "# we used a square kernel.  could do rectangle \"easily\".  for other kernels:\n",
    "# Rectangular  Elliptical  Cross kernels\n",
    "# cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "# cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "# cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Morphology and Spy Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bigger project includes morphology\n",
    "# from LOCV pg 142\n",
    "# image with/without object\n",
    "#      morph_open(thresh(abs(w - wo))\n",
    "# ---> noisy mask for object\n",
    "#      floodfill, keep largest only (see LOCV: pg 124)\n",
    "# ---> clean mask for object\n",
    "# ---> insert object into another photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing Pyramids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider five different gaussian pyramids:\n",
    "\n",
    "  * (1) one on the rgb image, \n",
    "  * (1) on the grayscale of the RGB image, and \n",
    "  * (3) one on each of the three channels in isolation\n",
    "\n",
    "Create a series of subplots for these over three pyramid levels.  This will give a grid of 20 total images if you include the originals.  Do the same for a Laplacian pyramid.  Use three levels of \"real\" Laplacians, with the base level being a Laplacian, not the Gaussian you might store for reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,5,figsize=(15,12))\n",
    "fig.tight_layout()\n",
    "\n",
    "apple, apple_g = my_read_cg(img_dir+'data/apple.png')\n",
    "\n",
    "def one_channel(img, c):\n",
    "    ' fixme:  seem hackish, but it sure works! '\n",
    "    out = np.zeros_like(img)\n",
    "    out[:,:,c] = img[:,:,c]\n",
    "    return out\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,5,figsize=(15,12))\n",
    "fig.tight_layout()\n",
    "\n",
    "apple, apple_g = my_read_cg(img_dir+'data/apple.png')\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a series of rectangles with narrower and narrower widths down to a single pixel line.  Apply a Sobel filter to these.  If Sobel filters find \"edges\", how many edges does the single pixel rectangle (that is, a \"line\") have?  Try using kernel sizes of 5 and 3.  Look at the numeric Sobel output values along a horizontal slice of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "widths = [1,2,4,8]\n",
    "height = 20\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Additional practice ideas:\n",
    "\n",
    "  * Research and implement a roberts edge detector\n",
    "      * apply it to binary image\n",
    "      * add noise - apply it.  \n",
    "      * https://dsp.stackexchange.com/questions/898/roberts-edge-detector-how-to-use\n",
    "  \n",
    "  * Predict what a distance transform would do to a checkerboard\n",
    "    * Try it out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 OpenCV3 (Forge)",
   "language": "python",
   "name": "opencv-forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
