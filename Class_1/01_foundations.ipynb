{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is setup to get a running opencv-3 environment.  We will be using conda-forge because the opencv in stock conda is older.\n",
    "\n",
    "We will follow a process similar to:\n",
    "\n",
    "  * [Kernels for different environments](https://ipython.readthedocs.io/en/latest/install/kernel_install.html#kernels-for-different-environments) and\n",
    "  * [Installing Different Kernels](https://ipython.readthedocs.io/en/latest/install/kernel_install.html#kernels-for-python-2-and-3)\n",
    "\n",
    "except we will also be pulling in dependencies from a non-stock conda repository called `conda-forge`.  `conda-forge` is a community-driven resource for package recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Mac/Linux enter the following in a terminal window:\n",
    "```\n",
    "    conda update conda\n",
    "    conda create --name opencv-forge --clone root\n",
    "    source activate opencv-forge\n",
    "    conda install -c conda-forge opencv\n",
    "    conda install ipykernel\n",
    "    python -m ipykernel install --user --name opencv-forge --display-name \"Py3 OpenCV3 (Forge)\"\n",
    "```\n",
    "\n",
    "[FIXME VERIFY] \n",
    "On Windows, open an Anaconda Command Prompt\"Start Menu -> Anaconda 64-bit -> Anaconda Prompt\" and enter:\n",
    "\n",
    "```\n",
    "    conda update conda\n",
    "    conda create --name opencv-forge --clone root\n",
    "    source activate opencv-forge\n",
    "    conda install -c conda-forge opencv\n",
    "    conda install ipykernel\n",
    "    python -m ipykernel install --user --name opencv-forge --display-name \"Py3 OpenCV3 (Forge)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't worked with alternative conda environments and jupyter/ipython kernels before, you'll want to check out this:\n",
    "  * [Getting started with Conda](https://conda.io/docs/user-guide/getting-started.html)\n",
    "  \n",
    "Now, when you create a new Jupyter notebook, you can choose **Py3 OpenCV3 (Forge)** from a drop-down.  \n",
    "\n",
    "<img src=\"../common/images/jupyter-kernel-select.png\">\n",
    "\n",
    "You will also see **Py3 OpenCV3 (Forge)** in Jupyter under **File --> New Notebook** and **Kernel --> Change kernel**.  Selecting these really does something bigger than \"just\" changing the kernel:  it also enables *all* the packages in that environment.  So, in effect, it is really more similar to changing the entire environement.  One way of viewing a kernel is as an entry point to an environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundational Friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NumPy](http://www.numpy.org/) is the foundation of (almost?) all numerical computing - number crunching - in Python.  Everything from numerical methods to statistical analysis to linear algebra to, yes, computer vision is built on NumPy.  We won't be doing a full course worth of material on NumPy, but if you want to dive deeper, check out:\n",
    "  * [NumPy User Guide](https://docs.scipy.org/doc/numpy-1.13.0/user/index.html)\n",
    "  * [Scipy Lectures NumPy](http://www.scipy-lectures.org/intro/numpy/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # common abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are low-level data structures (very similar to a C array).  They have a fixed block of memory and a fixed datatype for the elements.  We also keep track of the array's shape, but shapes can be malleable.  Why?  The big block of memory is really just a 1-D thing (think of a ticker tape).  Any structure we put on it (say, 4 rows and 6 columns) will have some other ways of regularly chunking it (24 elements, 6x4, 8x3, 3x8, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_int = np.array([1,2,3]) # create array from a list\n",
    "\n",
    "# feel free to uncomment:\n",
    "#for attr in [\"\", \"size\", \"shape\", \"dtype\"]:\n",
    "#    print(\"array {:5s} {}\".format(attr, getattr(arr_int, attr, arr_int)))\n",
    "print(arr_int)\n",
    "print(arr_int.size, arr_int.shape, arr_int.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array(arr):\n",
    "    print(arr)\n",
    "    for attr in [\"size\", \"shape\", \"dtype\"]:\n",
    "        print(\"{:>5s} {}\".format(attr, getattr(arr, attr)))  # getattr(obj, \"attr\") --> obj.attr\n",
    "\n",
    "# create array from range of values ... and shape it with 3 rows, 4 cols\n",
    "arr_range = np.arange(12.0).reshape(3,4)\n",
    "show_array(arr_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other forms along with our most useful dtypes for computer vision:\n",
    "np.array([2,2], dtype=np.uint8)\n",
    "np.array([2,2], dtype=np.float64)\n",
    "np.array([2,2], dtype=np.int64)\n",
    "\n",
    "np.array([2,2]).astype(np.float64) # note:  temp array (int64) created\n",
    "np.array([2,2]).astype(np.uint8)   # note:  temp array and might lose info (64 bit -> 8 bit)\n",
    "\n",
    "np.uint8((2,2))\n",
    "np.float64([[2,2]])\n",
    "np.int64([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = np.random # not public radio\n",
    "arr_rnd = npr.randint(0, 256, size=(5,5))\n",
    "show_array(arr_rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing shapes *does not* copy the array\n",
    "alias = arr_rnd.reshape(25)\n",
    "alias[0] = -99\n",
    "print(alias[0], arr_rnd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing dtype DOES (must) copy the array\n",
    "arr_rnd_float = arr_rnd.astype(np.float64) # aka np.float np.float_\n",
    "arr_rnd_float[0,0] = -0.99                 # it's a 2D thing\n",
    "print(arr_rnd[0], arr_rnd_float[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can select out rows and columns\n",
    "arr_rnd[:2, 1]  # first two rows, column 1\n",
    "\n",
    "# we can apply operations to blocks of elements in one-shot\n",
    "arr_rnd[:2, :2] * 2\n",
    "\n",
    "# we can assign to block of elements\n",
    "arr_rnd[:2, :2] = 1\n",
    "arr_rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more important, and sometimes confusing, aspects of NumPy is the idea of *axes*.  The reason it is confusing is because a common phrase `axis=0` looks like it means different things at different times.  However, the fundamental definition is always the same.  Summing over `axis=0` means summing over the *outer-most* dimension of the array.  Phrased another way, it means we sum over the first of whatever dimensions (1, 5, 100) our array has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10).reshape(5,2)\n",
    "column_sums = arr.sum(axis=0)\n",
    "print(arr, arr.shape, column_sums, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, summing over the outer-most dimension means we loop over the outer-most dimension.  This means we add up over the \"visual rows\" (but be careful of relying on the visual cue!).  So, we end up with a result that \"looks like\" (careful!) a row:  it has two elements ... *which are the column sums*.  See the weirdness?  If we have *c* columns, to get our *c* column-sums, we *loop over the rows*.  You can think of this as accumulating a new \"row\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = arr.sum(axis=1)\n",
    "print(arr, arr.shape, arr.sum(axis=1), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we loop over the `axis=1` leads to `arr.shape[1]` gives 2 columns and add them up to produce a new \"pseudo-column\".  This pseudo-column holds *the row sums*.  Two other tid-bits:  \n",
    "  1.  The output looks like a \"row\".  Don't be fooled.  It is really a 1-D thing.  This is because we have \"summed out\" and hence, reduced, one dimension of the array.\n",
    "  2.  If you want a 2-D result, you can use an argument `keepdims=True`.  This keeps the dimension that we summed over (with a shape of 1).  This can simplify mathematics that combine the original array with the aggregated result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr, arr.shape, arr.sum(axis=1, keepdims=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build new arrays by \"pasting together\" sources arrays in a few ways.  The most general is `np.concatenate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think sum by looping over the rows to get new pseudo-row\n",
    "# think concatentate (join-together) these arrays by adding them row-wise\n",
    "# but really:  looping over the outermost dimension to get a new pseudo-outermost dimension\n",
    "#              think concatentate (join-together) these arrays by taking on to the outermost dimension\n",
    "column_sums = arr.sum(axis=0, keepdims=True)\n",
    "np.concatenate([arr, column_sums], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping over the second outermost dimension to get a new pseudo-secondmost dimension\n",
    "# think concatentate (join-together) these arrays by taking on to the second-outermost dimension\n",
    "column_sums = arr.sum(axis=1, keepdims=True)\n",
    "np.concatenate([arr, column_sums], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll may also see these:  \n",
    " * np.hstack, np.vstack, np.dstack (deprecated or at least discouraged)\n",
    " * np.stack (preferred to `np.[hvd]stack` above)\n",
    " * np.column_stack, np.row_stack (sometimes useful b/c they promote to 2-D)\n",
    " \n",
    "You can do everything they do with `np.concatenate`.  From a learning-efficiency perspective, get good with `np.concatenate` and let that be that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding axes\n",
    "arr = np.array([1,2,3])\n",
    "\n",
    "arr.reshape(1,3) # \"row vector\"\n",
    "arr.reshape(3,1) # \"col vector\"\n",
    "\n",
    "arr[np.newaxis, :] # \"row vector\"\n",
    "arr[:, np.newaxis] # \"col vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Matplotlib](https://matplotlib.org/) is the foundation of the standard plotting and graphics display in the Python universe.  Seaborn and Pandas both use it under-the-hood.  Jupyter Notebooks have tight integration with it.  Generally, we'll only be using its most basic features.  So, if you need to know more, you'll want to check out:\n",
    "  * [Matplotlib User's Guide](https://matplotlib.org/users/index.html)\n",
    "  * [Scipy Lecture Notes](http://www.scipy-lectures.org/intro/matplotlib/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIMME OUTLINE (remove when done)\n",
    "# OO versus matlab APIs\n",
    "# simple plots (plot x-y, scatter, histogram, imshow)\n",
    "# simple styling (removing spines, hiding axes, titles, labels, limits)\n",
    "# imshow ---> cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get going with matplotlib, we will \"always\" issue the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common abbreviation\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# jupyter notebook specific to have plots appear in the notebook\n",
    "%matplotlib inline               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example of a basic matplotlib graph.  One small note:  the \";\" (semi-colon) at the end of the last line is there to prevent Jupyter from printing out the evaluated value of the last line of the cell.  Feel free to remove it and see the difference (re-run the cell with it removed).  We simply add the semi-colon as a cosmetic touch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0,10, 100) # 100 evenly spaced points from 0 to 10 inclusive\n",
    "ys = np.exp(xs)  # y = e^x\n",
    "\n",
    "# fig = plt.gcf() # explicitly get the default (current) figure (holder for \"full\" graphic) (rarely needed)\n",
    "ax = plt.gca()    # explicitly get the default (current) drawing axis\n",
    "\n",
    "ax.plot(xs, ys) # basic graph from two sequences:  x-points and y-points        \n",
    "ax.set_title(\"Example Graph\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "# ax.axis('off');  # uncomment me to see the difference with/without spines and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "arr = npr.randint(0,10,20)\n",
    "ax.hist(arr, bins=10)\n",
    "\n",
    "ax.set_xlabel(\"Integer\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Integers\")\n",
    "\n",
    "import collections as co\n",
    "print(co.Counter(arr)) # pure python counts of occurances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most heavily used matplotlib command in this course is `imshow`.  We'll talk about more of the `imshow` details next week, but for now let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our idea here is grayscale image, black and white\n",
    "arr = np.array([[0,1],\n",
    "                [1,0]], dtype=np.float64)\n",
    "plt.gca().imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not quite.  we need to tell it to use a grayscale color mapping\n",
    "# note:  by default the range [0,1] is expanded to fill the [0,255] intensity scale\n",
    "#        so:  0--->0 (black) and 1--->255 (white)\n",
    "\n",
    "# also:  remove the x/y grid points (matplotlib calls these \"spines\") and the frame\n",
    "ax = plt.gca()\n",
    "ax.imshow(arr, cmap='gray')\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be using this pattern so frequently, we'll give it a name and wrap it up in a function.  Note, we set interpolation to bicubic for a default so that \"real world\" images look better when we display them.  We'll have to remember that so that we can \"turn it off\" (pass `interpolation=None` ... which really does nearest neighbor interpolation but is close to showing the data as it is).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIXME CODE\n",
    "# consider my_show --> show\n",
    "#          my_gshow --> show_bw or show_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# line 5:  def my_show(**kwargs) --> takes any \"extra\" keyword arguments and \n",
    "#                                    puts them in a dictionary named kwargs\n",
    "# line 7:  ax.imshow(**kwargs)   --> takes kwargs (a dictionary) and \n",
    "#                                    \"expands\" them into keyword arguments to imshow\n",
    "def my_show(ax, img, title=None, interpolation='bicubic', **kwargs):\n",
    "    ' helper to display an image on an axes without grid/spine '\n",
    "    ax.imshow(img, interpolation = interpolation, **kwargs)\n",
    "    ax.axis('off')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "def my_gshow(ax, img, title=None, cmap='gray', interpolation='bicubic', **kwargs):\n",
    "    ' helper to display an image, in grayscale, on an axes without grid/spine '\n",
    "    my_show(ax, img, title=title, cmap='gray', interpolation=interpolation, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we'll want to compare several images (before and after some processing step).  To do that, we'll want more than one matplotlib axis to draw on.  `subplots` gives us a convenient way to get the axes to work with.  Then, we can pass different axes on to our show functions.  A note on `figsize`:  you can look at `plt.rcParams['figure.figsize']` to see the default (and use `rcParams` as a dictionary to find other configuration options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(9,3))  # 1 row, 3 columns of figures\n",
    "\n",
    "# axes is a numpy array with nrows, ncols ... unless one of the values is 1 ... then it is a \n",
    "# 1-D thing (but see squeeze=True squeeze=False argument to subplots to keep dimensions)\n",
    "arr = np.array([[0,1],\n",
    "                [1,0]], dtype=np.float64)\n",
    "my_show(axes[0], arr)\n",
    "my_gshow(axes[1], arr)\n",
    "my_gshow(axes[2], arr, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(3,9))  # 1 row, 3 columns of figures\n",
    "axes = axes.flat # a 1-D iterable of the axes (row-major)\n",
    "\n",
    "# make three random tiny arrays\n",
    "rnd_arrays = [npr.randint(0,2,(2,2)) for i in range(3)]\n",
    "\n",
    "# we can use the axes.flat iterable in Python-fu\n",
    "# zip(seq1, seq2) gives (seq1[0], seq2[0]), (seq1[1], seq2[1]), ...\n",
    "# enumerate(seq, start) gives (start, seq[0]) (start+1,seq[1]) ...\n",
    "for idx, (ax, arr) in enumerate(zip(axes, rnd_arrays), 1):\n",
    "    my_gshow(ax, arr, interpolation=None, title=\"Array {}\".format(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you are now exposed to `Figure`s and `Axes`, let's take a second to look at them more closely.  In the following cell, we make the overall `Figure` gray and we place two axes on it.  You can control much of the styling of the components independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,facecolor='gray', figsize=(12,4), sharey=True)\n",
    "axes[0].plot([1,2,3], [10,20,30])\n",
    "axes[1].plot([1,5], [3,10], 'ro');\n",
    "# fig.savefig('test.png', transparent=True) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other quick note.  So far, we've completely used the \"object-oriented API\" for matplotlib.  We recommend getting figures and axes from `plt.` commands and then consistently using the OO-api.  We encourage you to use this for 99+% of your matplotlib code.  However, you might see code like the following that relies heavily on implicit figures/axes and uses many `plt.` functions directly.  Warning!  The `plt.` functions and the `ax.` methods *look very similar* but are used differently.  Mixing them will result in headaches and frustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0,10, 100) # 100 evenly spaced points from 0 to 10 inclusive\n",
    "ys = np.exp(xs)  # y = e^x\n",
    "\n",
    "# the following are examples of the (not recommended) MATLAB-like API\n",
    "plt.figure(figsize=(2,2)) # affects the implicit figure\n",
    "\n",
    "plt.plot(xs, ys)           # uses the implicit axis\n",
    "plt.title(\"Example Graph\") # compare with ax.set_title('Example Graph')\n",
    "plt.xlabel(\"Time\")         # compare with ax.set_xlabel('Time')\n",
    "plt.axis('off');           # compare with ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIXME:  content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OpenCV](http://opencv.org/) is XXXXX.\n",
    "  * [FIXME VERIFY] Python API docs are [included here](http://docs.opencv.org/3.0-last-rst/)\n",
    "\n",
    "\n",
    "For example, for `cv2.imread`:\n",
    "  * [Docs for OpenCV3 shows Python API](http://docs.opencv.org/3.0-last-rst/modules/imgcodecs/doc/reading_and_writing_images.html#imread)\n",
    "  * [Newer Docs for OpenCV3 - Missing Python API](http://docs.opencv.org/3.3.0/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56)\n",
    "  * [Older OpenCV2 Docs](http://docs.opencv.org/2.4.13.3/modules/highgui/doc/reading_and_writing_images_and_video.html#cv2.imread)  \n",
    "    * In some respects, the version 2.x docs seems more mature\n",
    "    * Not up-to-date\n",
    "    * There is some breakage (API differences) from 2.x -> 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vaguely looks like ~20 cells from the first vision notebook\n",
    "import cv2 # yes, we are using opencv version 3 :grumpyface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find version of opencv\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '../common/'\n",
    "messi_gray = cv2.imread(img_dir+'data/messi.jpg', 0)\n",
    "my_gshow(plt.gca(), messi_gray) # use the default axes for quick-and-dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use scipy to read in images:\n",
    "from scipy import ndimage\n",
    "img = ndimage.imread(img_dir+'data/messi.jpg') # default here is RGB\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_color = cv2.imread(img_dir+'data/messi.jpg') # default flag is 1 \"color\"\n",
    "\n",
    "print(type(messi_color), \n",
    "      messi_color.shape, \n",
    "      messi_color.dtype)\n",
    "\n",
    "my_show(plt.gca(), messi_color)\n",
    "# FAIL:  mishmash of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv is GBR; matplotlib is RGB.  \n",
    "my_show(plt.gca(), messi_color[:,:,::-1]) # walk last axis in opposite order (we'll never do this again!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better: explicitly convert the image to RGB\n",
    "messi_rgb = cv2.cvtColor(messi_color, cv2.COLOR_BGR2RGB)\n",
    "my_show(plt.gca(), messi_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these come up frequently.  we'll always want rgb (instead of bgr)\n",
    "# and we often need both rgb and grayscale (grayscale starts many processing steps)\n",
    "def my_read(filename):\n",
    "    ' read from an image file to an rgb '\n",
    "    img = cv2.imread(filename)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def my_read_cg(filename):\n",
    "    ' read from an image file to an rgb and a grayscale image array '\n",
    "    rgb = my_read(filename)\n",
    "    gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    return rgb, gray\n",
    "\n",
    "# now we can do this:\n",
    "messi_rgb = my_read(img_dir+'data/messi.jpg')\n",
    "\n",
    "# or if we need both\n",
    "messi_rgb, messi_gray = my_read_cg(img_dir+'data/messi.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Images as NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messi_rgb = my_read(img_dir+'data/messi.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since messi_rgb is \"just\" a NumPy array, we can do NumPy array things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messi_rgb[100,100],     # access a pixel\n",
    "      messi_rgb[300,:].shape) # sub-select a row; it's an array also.  take its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixels are people ... err ... arrays too\n",
    "pixel = messi_rgb[100,100]\n",
    "print(type(pixel),\n",
    "      pixel.shape,  # 1-D, scalar, array\n",
    "      pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# massi's right wrist has a white spot!\n",
    "messi_rgb[100:105,100:105]=[255,255,255] # white (note, our target pixel also had 3 spots to fill)\n",
    "my_show(plt.gca(), messi_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball_soi = messi_rgb[280:340, 330:390] # \"soi\" = square of interest :)\n",
    "messi_rgb[273:333, 100:160] = ball_soi  # copy to new area\n",
    "my_show(plt.gca(), messi_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# often we want to access color channels separately\n",
    "# split to separate arrays per color (costly, prefer to access by indexing)\n",
    "chans = r,g,b = cv2.split(messi_rgb)\n",
    "restored = cv2.merge((r,g,b))\n",
    "\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4,figsize=(12,3))\n",
    "axes = axes.flat\n",
    "\n",
    "# handle first as special case\n",
    "first_axis = next(axes)\n",
    "my_show(first_axis, messi_rgb)\n",
    "first_axis.set_title(\"original\")\n",
    "\n",
    "# display per channel images\n",
    "for ax, ch, name in zip(axes, chans, [\"R\", \"G\", \"B\"]):\n",
    "    my_gshow(ax, g)\n",
    "    ax.set_title(\"{} channel\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.split is a convenience wrapper around numpy's split command\n",
    "# aka, split on last axis into size(last axis) pieces\n",
    "r_np,_,_ = np.split(messi_rgb, messi_rgb.shape[-1], -1) \n",
    "print(r_np.shape,\n",
    "      np.allclose(r, r_np[:,:,0])) # only 1D in last axis, so index it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can often just use indexing directly (see line 9)\n",
    "# also show off matplotlib histograms\n",
    "\n",
    "color_to_index = {\"R\":0, \"G\":1, \"B\":2}  # map strings to appropriate index in \n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(12,3), sharey=True)\n",
    "for ax, color in zip(axes, color_to_index):\n",
    "    c = color_to_index[color]\n",
    "    this_channel = messi_rgb[:,:,c].ravel() # 1D view without copying \n",
    "    \n",
    "    ax.hist(this_channel, 256, normed=True)\n",
    "    ax.set_title(\"Histogram for {}\".format(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(6,6))\n",
    "axes = axes.flat\n",
    "\n",
    "messi = my_read(img_dir+'data/messi.jpg')\n",
    "my_show(next(axes), messi, title=\"Size:{}\".format(messi.shape[:2]))\n",
    "\n",
    "borders = [cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_CONSTANT]\n",
    "for ax, border in zip(axes, borders):\n",
    "    with_border = cv2.copyMakeBorder(messi, 50,50,50,50,border)\n",
    "    my_show(ax, with_border, title=\"Size:{}\".format(with_border.shape[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gathering the setup code.  \n",
    "# if you are doing the exercises in another notebook, make sure these are executed\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def show_array(arr):\n",
    "    print(arr)\n",
    "    for attr in [\"size\", \"shape\", \"dtype\"]:\n",
    "        print(\"{:>5s} {}\".format(attr, getattr(arr, attr)))  # getattr(obj, \"attr\") --> obj.attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1.  Read the documentation for `np.zeros`.\n",
    "    1.  The generic way:  google \"numpy zeros\"\n",
    "    2.  The python way:  `import numpy as np`, `help(np.zeros)`\n",
    "    3.  The jupyter way:  `import numpy as np`, `?np.zeros`\n",
    "    4.  The master way:   `import numpy as np`, `np.zeros( <after open-paren hit tab two or four times>`\n",
    "    \n",
    "  2.  We'll be interested in only a few `dtypes` in this class:  `np.float64`, `np.uint8`, `np.int64` [but there are more out there](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html).  Create a NumPy array using `np.zeros` that has:\n",
    "    1.  5 total elements in one dimension, floats\n",
    "    2.  12 total elements in two dimensions, small unsigned ints\n",
    "    3.  12 total elements in three dimensions, bigger signed ints\n",
    "    4.  display each of these using the `show_array` function from above\n",
    "  4.  `np.tile` is wonderfully useful to create \"grided\" patterns.  Let's explore it.\n",
    "    1.  Create a simple 2x2 array called `myarr`.\n",
    "    2.  Try the following versions of tile (execute the commands *and* check out the shape of the result):\n",
    "      1. `np.tile(myarr, 1)`\n",
    "      1. `np.tile(myarr, 2)`\n",
    "      1. `np.tile(myarr, (1,1))`, \n",
    "      1. `np.tile(myarr, (2,1))`\n",
    "      1. `np.tile(myarr, (1,2))`, \n",
    "      1. `np.tile(myarr, (2,2))`\n",
    "      1.  Now, try to predict what `crazy_tile = np.tile(myarr, (3,1,1))` will do.  Now do it yourself.\n",
    "    3.  With that final \"tiled\" array, trying to:\n",
    "      1.  Generate the sums over visual \"rows\", \"columns\", and what I like to \"panels\" (the outermost grouping of row-column 2-D looking things).  Be careful to remember that `axis=0` means \"outermost dimension\".   Visually, this means \"summing by looping over the panels of `crazy_tile`\".\n",
    "      2.  Take these sums (one at a time, not all together) and append them on to `crazy_tile` using `np.concatenate`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 1:  \n",
    "# just follow along\n",
    "\n",
    "# numpy 2:\n",
    "arrays = [np.zeros(5, np.float64), \n",
    "          np.zeros((3,4), np.uint8),\n",
    "          np.zeros((2,2,3), np.int64)]\n",
    "for arr in arrays:\n",
    "    show_array(arr)\n",
    "    \n",
    "# numpy 3\n",
    "myarr = np.array([[1,2], [3,4]])\n",
    "for args in (1,2,(1,1),(2,1),(1,2),(2,2)):\n",
    "    show_array(np.tile(myarr, args))\n",
    "\n",
    "# numpy 3\n",
    "crazy_tile = np.tile(myarr, (3,1,1))\n",
    "crazy_tile.sum(axis=1) # visual rows\n",
    "crazy_tile.sum(axis=2) # visual cols   (innermost)\n",
    "crazy_tile.sum(axis=0) # visual panels (outermost)\n",
    "\n",
    "# numpy 3\n",
    "for axis in [0,1,2]:\n",
    "    ax_sum = crazy_tile.sum(axis=axis, keepdims=True)\n",
    "    show_array(np.concatenate([crazy_tile, ax_sum], axis=axis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. Use `np.zeros` and `np.ones` to create a square NumPy array that represents an image with a black square centered inside an outer white square.  Let the sides of the inner black square be 1/2 the length of the sides of the outer white square. Display your result (remember to set `interpolation=None`).\n",
    "  2. Add noise to the square you just made and display the result.  One way to do that is (1) create a white-noise image and (2) select either the \"real\" image point or the \"white noise\" image point.\n",
    "  \n",
    "    You'll end up generating two random things:  the white-noise image and a selector.  To *use* the selector, break out `np.where(condition, take_if_true, take_if_false)`.  In a basic case, all three arguments have the same shape.  At a position in the result (which has the same shape as the inputs), if `condition` holds (it is true), result gets a value from the second argument.  Otherwise, a value from the third argument goes into the result.  Read the docs for `np.where` and try simple example or two to get a feel for how it works.  Building small, demonstrative examples is a monumentally important skill!\n",
    "  3.  To preview some important ideas that we will get to in week 3, let's spend a few minutes interpreting an image as a function with a numerical derivative.  Specifically, we'll take a slice of values (across a row or column) and look at the differences between values from one pixel to the next.  `np.diff` is tailor-made to do this.  With your centered square from the first matplotlib exercise, take the `np.diff` across the center row and center column.  Graph the row and its 1st-difference with `plt.plot`.  *GOTCHA WARNING: `np.diff` has two gotchas.  (1)  calling it on `arr` will result in an array with `dtype==arr.dtype`.  The square you made is (possibly) a `np.uint8` array.  But, you can fix it!  (2)  `np.diff` results in an array smaller than the input because there is no difference for the first element.  There are a few ways around that.  Pick one.*\n",
    "  3.  NumPy and Matplotlib Graduation Day.  Use `np.zeros`, `np.ones`, `np.tile`, and `imshow` to create and display a black-and-white chessboard.  Chessboards are an 8x8 grid of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib exercise 1,2\n",
    "fig,axes = plt.subplots(1,2,figsize=(12,4))\n",
    "axes = axes.flat\n",
    "\n",
    "shape = (300,300)\n",
    "\n",
    "orig = np.zeros(shape, dtype=np.uint8)\n",
    "orig[75:225, 75:225] = 255\n",
    "my_gshow(next(axes), orig, interpolation=None)\n",
    "\n",
    "# not ultra efficient\n",
    "blur = np.random.randint(0,256,size=shape).astype(np.uint8)\n",
    "blurred = np.where(np.random.uniform(size=shape) > .3, orig, blur)\n",
    "my_gshow(next(axes), blurred, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3, warm up\n",
    "test = np.array([1,3,5,10])\n",
    "print(np.diff(test), \n",
    "      test[:-1] + np.diff(test)) # to recreate original (except first point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3\n",
    "row_slice = orig[150,:]\n",
    "print(row_slice.min(), row_slice.max())\n",
    "\n",
    "row_diff = np.diff(row_slice.astype(np.int16)) # otherwise diff loses sign\n",
    "print(row_diff.min(), row_diff.max())\n",
    "\n",
    "plt.plot(np.arange(299), row_slice[:-1], 'r') # could also use row_slice[1:] to align \"at\" jump\n",
    "plt.plot(np.arange(299), row_diff, 'b');      # no diff for first elt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 4\n",
    "\n",
    "# strategy:  create the top-left corner and then duplicate it with tile\n",
    "# base squares\n",
    "base_len = 100\n",
    "black = np.zeros((base_len, base_len), dtype=np.uint8)\n",
    "white = np.full_like(black, 255)\n",
    "\n",
    "# top-left corner\n",
    "# .c_ / .r_ create by specifying columns / rows using [] notation\n",
    "# can also use concatenate along axis=1 for np.c_ and axis=0 for np.r_\n",
    "top_left = np.c_[np.r_[white,black], np.r_[black,white]]\n",
    "\n",
    "# tiled out\n",
    "board = np.tile(top_left, (4,4))\n",
    "my_gshow(plt.gca(), board, interpolation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises with OpenCV and NumPy Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get a first look at the OpenCV documentation and practice making an OpenCV call.  We'll do much more of this next week!  Find the online documentation for `copyMakeBorder` and read it.  Yes, it might be painful - but, you'll need to develop this skill - reading online documentation - to master all that OpenCV (and other open-source software) has to offer.  \n",
    "\n",
    "Experiment with different arguments to `copyMakeBorder` and compare histograms of the image before and after.  You might want to \"turn off\" `sharey` and `normed` from the code above to see the effect they have.\n",
    "\n",
    "Above, we made three histograms in one row of a `subplots` set of axes.  Can you place the original and modified histograms over-under each other in two rows of a `subplots`?\n",
    "\n",
    "Lastly, copy a region-of-interest from one part of the image to another, using NumPy array operations.  You'll need to deal with the fact that an assignment within NumPy arrays must be from a source and a destination with the same size (this isn't strictly true, but we'll use it as a simplification for this exercsise -- if you want to know more, look up broadcasting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs at:\n",
    "# https://docs.opencv.org/3.0-beta/modules/core/doc/operations_on_arrays.html#copymakeborder\n",
    "# make sure you find the opencv 3 docs\n",
    "\n",
    "outdoors = my_read(img_dir+'data/farm-drop.jpg')\n",
    "with_border = cv2.copyMakeBorder(outdoors, 20,20,20,20,cv2.BORDER_CONSTANT)\n",
    "my_show(plt.gca(), with_border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_to_index = {\"R\":0, \"G\":1, \"B\":2}\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(12,3), sharey=True)\n",
    "for column, color in enumerate(color_to_index):\n",
    "    for row, img in enumerate([outdoors, with_border]): \n",
    "        c = color_to_index[color]\n",
    "        this_channel = img[:,:,c].ravel()\n",
    "\n",
    "        axes[row, column].hist(this_channel, 256, normed=True)\n",
    "        axes[0,column].set_title(\"Histogram for {}\".format(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next lesson, we'll learn about drawing, this is another option to track down\n",
    "# your region of interest\n",
    "marked_up = cv2.rectangle(outdoors, (1000,80), (1500, 800), (255,255,255), 10)\n",
    "my_show(plt.gca(), marked_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the ROI in another part of the image\n",
    "roi = marked_up[81:800, 1001:1500]\n",
    "shape = roi.shape\n",
    "marked_up[10:10+shape[0],10:10+shape[1]] = roi\n",
    "my_show(plt.gca(), marked_up)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 OpenCV3 (Forge)",
   "language": "python",
   "name": "opencv-forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
