{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utilities import my_show, my_gshow, my_read, my_read_g, my_read_cg, size_me\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The basic steps that Canny performs are:\n",
    "  * remove noise with 5x5 gaussian\n",
    "  * horizontal & vertical edge detection\n",
    "  * suppress non-maximums (in direction of gradient)\n",
    "  * connect above maxval to intermediate / drop below min val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messi = my_read_g('data/messi.jpg')\n",
    "\n",
    "edges_1 = cv2.Canny(messi, 100, 200)                   # L1 norm g1/g2\n",
    "edges_2 = cv2.Canny(messi, 100, 200, L2gradient=True)  # L2 norm g1/g2\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,10))\n",
    "my_show(axes[0], messi, cmap='gray')\n",
    "my_show(axes[1], edges_1, cmap='gray')\n",
    "my_show(axes[2], edges_2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the Fourier Transform and the FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This [tutorial](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/) is really, really good and really, really worth reading if you want to understand the FFT.  But, we'll try to give you some insight here.  In the following example, there will be some \"weird\" notation.  Please just squint your eyes, take a deep breath, and say \"there is no spoon\" (apologies to The Matrix).  In seriousness, we are going to make very brief use of *complex numbers*.  But, *it doesn't matter* - and we will prove it to you in a few minutes.\n",
    "\n",
    "For now, all you need to think about is that a \"complex number\" is really just wrapping up a 2D point (with an x- and y- value) into *one object*.  For the programmers out there, it is just like saying `value = (x,y)`:  `value` is a pair composed of two primitive parts.  This is the same thing we do when we have datapoints in 2D space:  `value = (ftr_1, ftr_2)`.  So, when you see some python code that looks like `value = 2+3j` just keep in mind we are really just doing a \"mathematical hack\" to say `value = (2,3)` in a different form.\n",
    "\n",
    "One other note:  to get the working examples, we have to dive into some of the ugly underside of FFT implementations.  In particular, you'll see some `fftshift` calls below.  We'll get into some of the idea behind these with smaller examples in a bit.  But briefly, when we compute the FFT we get results that look like:  $f_0, f_1, ... f_{n-1}, f_{-1}, f_{-1}, f_{-2}, ..., f_{-(n-1)}$.  That is, $f_0$ is *not* in the middle.  It's on the left-hand end of the results.  `fftshift` undoes that and puts the results in a more natural order:  $f_{-(n-1)}, ..., f_{-1}, f_0, f_1, ... f_{n-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 5 points in the 2D plane (really the complex plane)\n",
    "star_outer_points = np.array([np.exp(4.0j*np.pi*x/5.) for x in range(6)])\n",
    "print(star_outer_points.shape,\n",
    "      star_outer_points, sep='\\n')\n",
    "\n",
    "# for the plot of the star points: \n",
    "#      x is \"real part\" (first value in the tuple-like thing) \n",
    "#      y is \"imaginary\" (second value in the tuple-like thing)\n",
    "\n",
    "# we have 6 points, matplotlib fills in lines between them\n",
    "# (that's what the \"-\" argument says explicitly)\n",
    "plt.plot(star_outer_points.real, star_outer_points.imag, 'or', label='outer points');\n",
    "plt.plot(star_outer_points.real, star_outer_points.imag, '-b', label='filled lines');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear interpolation between points in plane basically\n",
    "# draws lines between those points ... just like plt.plot does (see above)\n",
    "# \n",
    "# this creates a function that we can call to get results\n",
    "# we create a function that maps an input between 0,2pi to a position on the star\n",
    "# we use [0, star point 0], ...., [2pi, start point 5]\n",
    "#     as the fixed part and interpolate between them\n",
    "from scipy.interpolate import interp1d\n",
    "star_func = interp1d(np.linspace(0., 2*np.pi, num=len(star_outer_points)), \n",
    "                     star_outer_points)\n",
    "\n",
    "# why do we care about circles?  beacuse Fourier methods translate \n",
    "# \"normal\" functions to combinations of circles (and back again)\n",
    "\n",
    "# think about this as mapping between how far you have walked around a circle\n",
    "# and how far you have walked over the drawing of the star\n",
    "# 200 points around a circle, also get the size of one step around the circle\n",
    "N = 200\n",
    "circle_steps, step_size = np.linspace(0., 2*np.pi, N, retstep=True)\n",
    "star_points = star_func(circle_steps)\n",
    "\n",
    "print(\"number of data points:\", star_points.shape)\n",
    "\n",
    "plt.plot(star_outer_points.real, star_outer_points.imag, 'or', label='outer points')\n",
    "plt.plot(star_points.real, star_points.imag, 'b.', label='data points')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we have a very simple drawing (in two dimensions):  it has 200 discrete values that are our data.  If we have a 20 x 30 image, we would have 600 values as our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform our Discrete Fourier Transform from our *data space* to what we'll call *circle space* (any higher mathematicians in the audience can groan, if they'd like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_points = star_func(circle_steps)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 9))\n",
    "#\n",
    "# Draw our data points \n",
    "# (which we created by interpolating, filling in between the star points) \n",
    "#\n",
    "axes[0,0].plot(star_points.real, star_points.imag, 'b.', label='input data')\n",
    "axes[0,0].set_title(\"Original Data Points\")\n",
    "axes[1,0].set_visible(False)\n",
    "\n",
    "#\n",
    "# Perform a DFT using FFT on our data points\n",
    "# Use *all* of the DFT results to recreate our original data\n",
    "#\n",
    "dft = np.fft.fft(star_points)\n",
    "full_inverse = np.fft.ifft(dft)\n",
    "axes[0,1].plot(full_inverse.real, full_inverse.imag, 'r+')\n",
    "axes[0,1].set_title(\"Full Reconstruction\")\n",
    "\n",
    "#\n",
    "# Do some trickery to look at the DFT(orig) in circle space\n",
    "# circle space is really the \"freqency domain\" (hence freqs)\n",
    "# https://en.wikipedia.org/wiki/Frequency_domain\n",
    "#\n",
    "freqs = np.fft.fftfreq(N, step_size)\n",
    "graph_coeffs = (1.0/N) * np.abs(np.fft.fftshift(dft))\n",
    "graph_freqs  = np.fft.fftshift(freqs)\n",
    "axes[1,1].plot(graph_freqs, graph_coeffs)\n",
    "axes[1,1].set_ylim(0, .25)\n",
    "axes[1,1].set_xlim(-5, 5)\n",
    "axes[1,1].set_title(\"Full Fourier Frequencies\")\n",
    "\n",
    "\n",
    "#\n",
    "# Now, throw-out the frequencies that are \"big\"\n",
    "# do that by assigning 0 to not-low freqs\n",
    "# (note, we update dft in place)\n",
    "#\n",
    "low_freqs = abs(freqs) < .5\n",
    "print(\"keeping {} frequencies\".format(low_freqs.sum()))\n",
    "dft[~low_freqs] = 0.0\n",
    "part_inverse = np.fft.ifft(dft)\n",
    "axes[0,2].plot(part_inverse.real, part_inverse.imag, 'r+');\n",
    "axes[0,2].set_title(\"Partial Reconstruction\")\n",
    "\n",
    "#\n",
    "# extract out a visual of trimmed-DFT(orig)\n",
    "#\n",
    "graph_coeffs = (1.0/N) * np.abs(np.fft.fftshift(dft))\n",
    "graph_freqs  = np.fft.fftshift(freqs)\n",
    "axes[1,2].plot(graph_freqs, graph_coeffs)\n",
    "axes[1,2].set_ylim(0, .5)\n",
    "axes[1,2].set_xlim(-3, 3)\n",
    "axes[1,2].set_title(\"Trimmed Fourier Frequencies\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we cut out the highest frequencies, this is removing information about what happens when the data changes very abruptly.  This is exactly what happens at the outer points of the star.  So, we see that removing those high freqencies results in a rounding of the sharp peaks.\n",
    "\n",
    "Now, let's demonstrate that there's *no practical difference* when we work with standard 2D data - we simple eliminate this complex, ahem, complexity.  There is one mathematical difference that the clever reader may notice:  when we apply a DFT to data that is purely real-numbers, the resulting DFT is symmetric.  So, the DFT above and the DFT below will be slightly different.  However, the reconstructed star is the same.  The mathematics work out slightly differently, but cancel out, under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert star_points to standard 2D data\n",
    "star_points = star_func(circle_steps)\n",
    "star_points = np.c_[star_points.real, star_points.imag]\n",
    "print(star_points.shape, star_points.dtype)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 9))\n",
    "\n",
    "#\n",
    "# Draw our data points \n",
    "# (which we created by interpolating, filling in between the star points) \n",
    "#\n",
    "axes[0,0].plot(star_points[:,0], star_points[:,1], 'b.', label='input data')\n",
    "axes[0,0].set_title(\"Original Data Points\")\n",
    "axes[1,0].set_visible(False)\n",
    "\n",
    "#\n",
    "# Perform a DFT using FFT on our data points\n",
    "# Use *all* of the DFT results to recreate our original data\n",
    "# NOTE:  using \"real-numbered\" version (not complex) and 2D \n",
    "#\n",
    "dft = np.fft.rfft2(star_points)\n",
    "full_inverse = np.fft.irfft2(dft)\n",
    "axes[0,1].plot(full_inverse[:,0], full_inverse[:,1], 'r+')\n",
    "axes[0,1].set_title(\"Full Reconstruction\")\n",
    "\n",
    "#\n",
    "# Do some trickery to look at the DFT(orig) in circle space\n",
    "# circle space is really the \"freqency domain\" (hence freqs)\n",
    "# https://en.wikipedia.org/wiki/Frequency_domain\n",
    "#\n",
    "freqs = np.fft.fftfreq(N, step_size)\n",
    "graph_coeffs = (1.0/N) * np.abs(np.fft.fftshift(dft))\n",
    "graph_freqs  = np.fft.fftshift(freqs)\n",
    "axes[1,1].plot(graph_freqs, graph_coeffs)\n",
    "axes[1,1].set_ylim(0, .25)\n",
    "axes[1,1].set_xlim(-5, 5)\n",
    "axes[1,1].set_title(\"Full Fourier Frequencies\")\n",
    "\n",
    "\n",
    "#\n",
    "# Now, throw-out the frequencies that are \"big\"\n",
    "# do that by assigning 0 to not-low freqs\n",
    "# (note, we update dft in place)\n",
    "#\n",
    "low_freqs = abs(freqs) < .5\n",
    "print(\"keeping {} frequencies\".format(low_freqs.sum()))\n",
    "dft[~low_freqs] = 0.0\n",
    "part_inverse = np.fft.irfft2(dft)\n",
    "axes[0,2].plot(part_inverse[:,0], part_inverse[:,1], 'r+');\n",
    "axes[0,2].set_title(\"Partial Reconstruction\")\n",
    "\n",
    "#\n",
    "# extract out a visual of trimmed-DFT(orig)\n",
    "#\n",
    "graph_coeffs = (1.0/N) * np.abs(np.fft.fftshift(dft))\n",
    "graph_freqs  = np.fft.fftshift(freqs)\n",
    "axes[1,2].plot(graph_freqs, graph_coeffs)\n",
    "axes[1,2].set_ylim(0, .5)\n",
    "axes[1,2].set_xlim(-3, 3)\n",
    "axes[1,2].set_title(\"Trimmed Fourier Frequencies\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Methods \"in the Small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few image pairs that take us from simple images to their \"circle-domain\".  Run these with different inputs to see what happens to the DFT output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this test image has only 11x11 -> 121 total data points \n",
    "# and is VERY granular\n",
    "box = np.zeros((11,11), dtype=np.float64)\n",
    "box[4,4] = 1.0  # shifting this does interesting things\n",
    "#box[:,:] = 1.0  # everything the same value -- \"constant\" freqency only\n",
    "\n",
    "#box[3,3] = box[7,7] = box[3,7] = box[7,3] = 1.0\n",
    "#box[5,5] = 1.0\n",
    "#box[5,2] = box[5,9] = 1.0\n",
    "\n",
    "fft = np.fft.fft2(box)\n",
    "#fft = cv2.dft(box, flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "# print(fft)\n",
    "#print(fft.shape)\n",
    "\n",
    "shifted = np.fft.fftshift(fft)\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "my_gshow(axes[0], box, interpolation=None)\n",
    "my_gshow(axes[1], np.abs(shifted), interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = np.zeros((11,11), dtype=np.float64)\n",
    "# adding this gives a cool frequency pattern\n",
    "box[5,5] = 1.0\n",
    "box[3,3] = box[7,7] = box[3,7] = box[7,3] = 1.0\n",
    "\n",
    "fft = np.fft.fft2(box)\n",
    "shifted = np.fft.fftshift(fft)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(15, 15))\n",
    "my_gshow(axes[0], box, interpolation=None)\n",
    "#my_gshow(axes[1], np.abs(fft), interpolation=None)\n",
    "my_gshow(axes[1], np.abs(shifted), interpolation=None)\n",
    "#my_gshow(axes[2], np.abs(np.fft.ifft2(fft)), interpolation=None)\n",
    "#my_gshow(axes[2], np.real(np.fft.ifft2(fft)), interpolation=None)\n",
    "\n",
    "keep = 11\n",
    "padded = np.zeros_like(box, dtype=np.complex64)\n",
    "padded[:keep, :keep] = fft[:keep, :keep]\n",
    "my_gshow(axes[2], np.real(np.fft.ifft2(padded)), interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = np.zeros((200,200), dtype=np.float64)\n",
    "img = cv2.circle(img, (100,100), 50, 2)\n",
    "\n",
    "fft = np.fft.fft2(img)\n",
    "shifted = np.fft.fftshift(fft)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(15, 15))\n",
    "my_gshow(axes[0], img, interpolation=None)\n",
    "my_gshow(axes[1], np.abs(shifted), interpolation=None)\n",
    "\n",
    "# by the time we hit 200, we have the full circle\n",
    "# the tails get rid of the noise in the background\n",
    "# and refine the boundaries of the circle\n",
    "keep = 25\n",
    "padded = np.zeros_like(img, dtype=np.complex64)\n",
    "padded[:keep, :keep] = fft[:keep, :keep]\n",
    "my_gshow(axes[2], np.real(np.fft.ifft2(padded)), interpolation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FFT on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi = my_read_g('data/messi.jpg')\n",
    "\n",
    "fft = np.fft.fft2(messi)\n",
    "# note, we've shifted to get (0,0) in the center\n",
    "# and,  we've taken the log and multiplied by 20 to let the smaller values \n",
    "#       compete with the bigger values (better contrast)\n",
    "# if you don't, you a flat black result (with maybe a white point in the middle)\n",
    "# frequency_spectrum = np.abs(np.fft.fftshift(fft))\n",
    "frequency_spectrum = 20*np.log(np.abs(np.fft.fftshift(fft)))\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,6))\n",
    "my_gshow(axes[0], messi)\n",
    "my_gshow(axes[1], frequency_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in frequency domain, we can do \"frequency based techniques\" like:\n",
    "# \"high pass filtering\" (remove low frequencies)\n",
    "# in images, a high frequency is an edge (or another quick change) \n",
    "\n",
    "def slice_middle(arr, pm):\n",
    "    ' for each dim of arr, take the (m // 2) +- pm middle slice '\n",
    "    slices = [slice(m // 2 - pm, m//2 + pm) for m in arr.shape]\n",
    "    return slices\n",
    "\n",
    "# center the fft, \n",
    "# zero out the center (low-freq components)\n",
    "# decenter\n",
    "# [the \"center\" of the shifted FFT pulls together the four corners \n",
    "#  of the uncentered version to the middle (like a high-school xy axis)\n",
    "fshift = np.fft.fftshift(fft)\n",
    "fshift[slice_middle(fshift, 30)] = 0\n",
    "fft_cut = np.fft.ifftshift(fshift)\n",
    "\n",
    "# invert the fft; abs() since we used the general fft\n",
    "messi_back = np.abs(np.fft.ifft2(fft_cut))\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,10))\n",
    "my_gshow(axes[0], messi, cmap='gray')\n",
    "my_show(axes[1], messi_back, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanted to do that without using slice_middle helper\n",
    "# it would look like this:\n",
    "fft_cp = fft.copy()\n",
    "fft_cp[:30, :30]  = fft_cp[-30:, -30:] =0 # top left/bot right corners\n",
    "fft_cp[-30:, :30] = fft_cp[:30, -30:] = 0 # bot left/ top right corners\n",
    "messi_back = np.abs(np.fft.ifft2(fft_cp))\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(15,10))\n",
    "my_show(axes[0], messi, cmap='gray')\n",
    "my_show(axes[1], messi_back, cmap='jet'); # slightly better contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar process using opencv's DFT code\n",
    "dft = cv2.dft(np.float64(messi), flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "# remove high frequency components (i.e., details)\n",
    "# ---> should give us a blurred image\n",
    "# use mask and multiple to remove freqs\n",
    "mask = np.zeros_like(dft_shift, dtype=np.bool)\n",
    "mask[slice_middle(mask, 30)] = True\n",
    "\n",
    "# mask, unshift, invert dft\n",
    "messi_back = cv2.idft(np.fft.ifftshift(dft_shift * mask))\n",
    "messi_back = cv2.magnitude(messi_back[:,:,0], messi_back[:,:,1])\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,10))\n",
    "my_show(axes[0], messi, cmap='gray')\n",
    "my_show(axes[1], messi_back, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of FFT is improved by having \"optimal\" array sizes\n",
    "opt_r, opt_c = [cv2.getOptimalDFTSize(d) for d in messi.shape]\n",
    "messi.shape, (opt_r, opt_c)\n",
    "\n",
    "# we enforce this by either \n",
    "# 1.  new numpy array (zeros/empty); put image in top-left\n",
    "# 2.  using cv2.copyMakeBorder (ugh)\n",
    "\n",
    "# results in about 4x speedup ... but note, we are also spending time/memory\n",
    "# to do the setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters, Fourier, and Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple averaging filter without scaling parameter\n",
    "mean_filter = np.ones((3,3))\n",
    "\n",
    "# creating a guassian filter\n",
    "gk = cv2.getGaussianKernel(5,10)\n",
    "gaussian = gk*gk.T\n",
    "\n",
    "# different edge detecting filters\n",
    "# laplacian\n",
    "laplacian=np.array([[0, 1, 0],\n",
    "                    [1,-4, 1],\n",
    "                    [0, 1, 0]])\n",
    "\n",
    "# sobel in x direction\n",
    "sobel_x= np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0, 1]])\n",
    "# sobel in y direction\n",
    "sobel_y= sobel_x.T\n",
    "\n",
    "# scharr in x-direction\n",
    "scharr = np.array([[-3, 0, 3],\n",
    "                   [-10,0,10],\n",
    "                   [-3, 0, 3]])\n",
    "\n",
    "def mag_fft(arr):\n",
    "    # use log(1+p) to prevent log(0)\n",
    "    return np.log1p(np.abs(np.fft.fftshift(np.fft.fft2(arr))))\n",
    "\n",
    "filters = [mean_filter, gaussian, laplacian, sobel_x, sobel_y, scharr]\n",
    "filter_names = ['mean filter', 'gaussian', 'laplacian', \n",
    "                'sobel x', 'sobel y', 'scharr x']\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=(8,5))\n",
    "for name, filt, ax in zip(filter_names, filters, axes.flat):\n",
    "    # interesting variations:  \n",
    "    # cmap='gray', 'jet', default; interpolation = None\n",
    "    my_show(ax, mag_fft(filt), cmap='jet')\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.filter2D` will use the DFT of the image and the DFT of the kernel to do a fast \"convolution\" when it is warranted.  The reason why I say convolution in quotes is because `filter2D` really does something annoyingly similar to convolution called *correlation*.  The difference is whether the kernel is flipped before applying it.  Now, two points:  (1) if the kernel is symmetric, it doesn't matter and (2) in terms of our earlier discusions, flipping the kernel really has to do with how we align the neighborhoods of the image and the kernel.  So, all that aside:  you can use `filter2D` with symmetric kernels.  If you want to apply a specific, non-symmetric kernel and/or force the use of DFT all the time, you can either read the docs for `filter2D` or apply a DFT manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with wavelet methods, we'll make use of the nice pywavelets package.\n",
    "\n",
    "    conda search pywavelets\n",
    "    conda install pywavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "messi = my_read_g('data/messi.jpg')\n",
    "\n",
    "wave_coeffs = pywt.wavedec2(messi, 'haar', 4)\n",
    "wave_coeffs[0] *= 0.0\n",
    "recon = pywt.waverec2(wave_coeffs, 'haar')\n",
    "\n",
    "print(abs(messi - recon).sum())\n",
    "\n",
    "my_gshow(plt.gca(), recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose to \n",
    "# approximation for level 2\n",
    "# detail coefficients for other levels\n",
    "cA2, (cH2, cV2, cD2), (cH1, cV1, cD1) = pywt.wavedec2(messi, 'haar', level=2)\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,10))\n",
    "axes[0,0].set_visible(False)\n",
    "my_gshow(axes[0,1], cH1); axes[0,1].set_title(\"Level 1 (Horz Detail)\")\n",
    "my_gshow(axes[1,0], cV1); axes[1,0].set_title(\"Level 1 (Vert Detail)\")\n",
    "my_gshow(axes[1,1], cD1); axes[1,1].set_title(\"Level 1 (Diag Detail)\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(16,10))\n",
    "my_gshow(axes[0,0], cA2); axes[0,0].set_title(\"Level 2 (Approximation)\")\n",
    "my_gshow(axes[0,1], cH2); axes[0,1].set_title(\"Level 2 (Horz Detail)\")\n",
    "my_gshow(axes[1,0], cV2); axes[1,0].set_title(\"Level 2 (Vert Detail)\")\n",
    "my_gshow(axes[1,1], cD2); axes[1,1].set_title(\"Level 2 (Diag Detail)\")\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Line Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.zeros((500,500), np.uint8)\n",
    "cv2.line(test_img,(50,400),(400,125),255,2)\n",
    "\n",
    "blur = np.random.randint(0,256,size=test_img.shape).astype(np.uint8)\n",
    "blurred = np.where(np.random.uniform(size=test_img.shape) > .2, test_img, blur)\n",
    "\n",
    "my_show(plt.gca(), blurred, cmap='gray', interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)\n",
    "out = cv2.cvtColor(blurred, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def rho_theta_to_intercepts_1(rho_th):\n",
    "    rho, theta = rho_th\n",
    "\n",
    "    # r,theta -> x,y\n",
    "    cos_th, sin_th = np.cos(theta), np.sin(theta)\n",
    "    x_mid, y_mid = rho * cos_th, rho * sin_th\n",
    "\n",
    "    # slope is negative reciprocal of the perpendicular\n",
    "    slope = -x_mid / y_mid\n",
    "\n",
    "    # (y-y_1) = m(x-x_1) ... solve for y=0 (x_int) and x=0 (y_int)\n",
    "    x_int = -y_mid / slope + x_mid\n",
    "    y_int = -slope * x_mid + y_mid\n",
    "\n",
    "    return x_int, y_int\n",
    "\n",
    "def rho_theta_to_intercepts_2(rho_th):\n",
    "    # via more trig & inscribing x_mid,y_mid square in larger triangle\n",
    "    # calculate additional pieces outside (x_plus, y_plus)\n",
    "    # fixme:  have trig notes on this stuff\n",
    "    rho, theta = rho_th\n",
    "    cos_th, sin_th, tan_th = np.cos(theta), np.sin(theta), np.tan(theta)\n",
    "    x_mid, y_mid = rho * cos_th, rho * sin_th\n",
    "    \n",
    "    x_int = x_mid + y_mid * tan_th\n",
    "    y_int = y_mid + x_mid / tan_th\n",
    "    return x_int, y_int    \n",
    "\n",
    "lines = cv2.HoughLines(thresh, 1, np.pi/180, 100)\n",
    "for rho_th in lines[0]:\n",
    "    x_int, y_int = rho_theta_to_intercepts_2(rho_th)\n",
    "    cv2.line(out, (0,y_int), (x_int,0), (0,0,255),2)\n",
    "\n",
    "my_show(plt.gca(), out)\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fortunately, probabilistic gives end points\n",
    "\n",
    "# min line len is required to be considered a line\n",
    "# gaps join to create single line\n",
    "lines = cv2.HoughLinesP(thresh,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n",
    "out = cv2.cvtColor(blurred, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "print(len(lines))\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(out,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "my_show(plt.gca(), out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocv_logo = my_read('data/opencv-logo.png')\n",
    "my_show(plt.gca(), ocv_logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocv_logo, ocv_logo_g = my_read_cg('data/opencv-logo.png')\n",
    "blurred = cv2.medianBlur(ocv_logo_g, 5)\n",
    "\n",
    "# crashes badly if no circles found\n",
    "circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                           param1=50, param2=30,\n",
    "                           minRadius=0, maxRadius=0)\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "white = (255,255,255)\n",
    "for x,y,r in circles[0,:]:\n",
    "    pt = (x,y)\n",
    "    # draw the outer and inner\n",
    "    cv2.circle(ocv_logo, pt, r, white, 2)\n",
    "    cv2.circle(ocv_logo, pt, 2, white, 3)\n",
    "my_show(plt.gca(), ocv_logo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Canny Edge Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the effects of different high and low thresholds in the Canny edge detector.  On a sample image, apply upper thresholds in the intervals between [50,100], [100,150], ..., [250,300] (six total upper thresholds).  Use three different lower thresholds for each upper threshold:  upper / 4, upper / 2.75, and upper / 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_g = my_read_g('data/messi.jpg')\n",
    "# fig, axes = plt.subplots(12, 3, figsize=(12, 24))\n",
    "fig, axes = plt.subplots(6, 3, figsize=(12, 15))\n",
    "    \n",
    "# Student section here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building FFT Intuition\n",
    "\n",
    "Create an image (say 100x100 pixels) with one white pixel (somewhere in the upper left corner).  Compute the *inverse* DFT of this image.  Display the real part and the imaginary part (separately) of the result.  Can you describe what you are seeing?  Repeat that process with a different white pixel turned \"on\".  And, finally, repeat the process with two white pixels turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student section here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FFT and Convolution\n",
    "\n",
    "Compare the timing of applying a Gaussian kernel directly to an image and the following FFT based process:\n",
    "\n",
    "  1.  compute the FFT of the Gaussian kernel\n",
    "  2.  compute the FFT of the image\n",
    "  3.  multiply the two FFTs\n",
    "  4.  invert the FFT of the result\n",
    "\n",
    "Try for kernels of size 4x4, 8x8, 16x16, and 32x32.\n",
    "\n",
    "There are a ridiculous number of convolution, correlation-convolution, and fft based methods in numpy and scipy.  Just in scipy signal and scipy ndimage, there are:\n",
    "       \n",
    "    ss.convolve, ss.convolve2d, ss.correlate, ss.correlate2d, ss.fftconvolve\n",
    "\n",
    "    nd.correlate, nd.correlate1d, nd.convolve, nd.convolve1d\n",
    "    nd.filters.<same>\n",
    "\n",
    "But, if you ever want to write your own pure NumPy convolution, you can do it in just a few lines of code:\n",
    "\n",
    "    def conv2d(a, f):\n",
    "        ''' black magic that walks through a in a special way, aligning as we go \n",
    "            credit:  https://stackoverflow.com/a/43087771/221602 '''\n",
    "        s = f.shape + tuple(np.subtract(a.shape, f.shape) + 1)\n",
    "        as_strided = np.lib.stride_tricks.as_strided\n",
    "        sub_arr = as_strided(a, shape = s, strides = a.strides * 2)\n",
    "        return np.einsum('ij,ijkl->kl', f, sub_arr)\n",
    "\n",
    "To keep things sane, here is a messy example and then some nice scipy examples of using DFT based convolution and using direct convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_g = my_read_g('data/messi.jpg')\n",
    "gk = cv2.getGaussianKernel(5,10)\n",
    "gaussian = gk*gk.T\n",
    "\n",
    "full_shape = np.sum(np.array(i.shape) for i in [messi_g, gaussian])\n",
    "fft_messi = np.fft.fft2(messi_g, full_shape)\n",
    "fft_gaussian = np.fft.fft2(gaussian, full_shape)\n",
    "\n",
    "# undoing the padding is horrendously ugly\n",
    "result = np.abs(np.fft.ifft2(fft_messi * fft_gaussian))[gaussian.shape[0]:messi_g.shape[0], \n",
    "                                                        gaussian.shape[1]:messi_g.shape[1]]\n",
    "my_gshow(plt.gca(), result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "# note, if mode equals full, we have to do the same annoying slicing we did above\n",
    "my_gshow(plt.gca(), fftconvolve(messi_g, gaussian, mode='same'), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "my_gshow(plt.gca(), convolve2d(messi_g, gaussian, mode='same'), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hough Transforms\n",
    "\n",
    "Apply the probabilistic Hough line transform and the Hough circle transform to a picture of a bicycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike, bike_g = my_read_cg('data/bike.jpg')\n",
    "\n",
    "# Student section here \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (intel_nlp)",
   "language": "python",
   "name": "intel_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
